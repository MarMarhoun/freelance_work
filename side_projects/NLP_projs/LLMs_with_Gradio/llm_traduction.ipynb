{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZ5xLBmTeI//TnJsZAy5r6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarMarhoun/freelance_work/blob/main/side_projects/NLP_projs/LLMs_with_Gradio/llm_traduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blohYfUmG-r7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web Application for Video Content Analysis and Translation using Gradio\n",
        "\n",
        "This code provides a comprehensive tool for users to analyze video content by extracting subtitles, summarizing them, checking for similarity with a given prompt, and translating text into multiple languages. The use of Gradio allows for an interactive and visually appealing user experience, making it easy for users to engage with the functionalities offered by the application.\n",
        "\n",
        "**Key Components and Functionalities**\n",
        "\n",
        "\n",
        "\n",
        "1.   **Subtitle Extraction:** The script initializes a similarity model using `SentenceTransformer` and a summarization model from the Hugging Face Transformers library. It defines a dictionary of translation models for various languages, including Arabic, Spanish, French, German, and Chinese, and loads them into translation pipelines.\n",
        "\n",
        "\n",
        "2.   **Subtitle Extraction:** The `extract_subtitles` function takes a YouTube video URL, extracts the video ID, and retrieves the transcript. It includes error handling for scenarios such as missing transcripts or unavailable videos, ensuring that users receive informative feedback.\n",
        "\n",
        "3.  **Text Processing Functions:** Several functions are defined to handle text processing tasks. The `save_extracted_text` function saves the extracted subtitles to a text file. The `create_wordcloud` function generates a word cloud image from the provided text and saves it as a PNG file. The `summarize_text` function summarizes the input text using the summarization model, truncating it if necessary. The `translate_text` function translates the input text into the selected target language, splitting long texts into smaller chunks to avoid errors during translation.\n",
        "\n",
        "4. **Text Extraction and Display:** The `extract_and_display_text` function combines the functionalities of subtitle extraction, word cloud generation, and text summarization. It returns the extracted text, summarized text, and paths to the generated word clouds, providing a comprehensive overview of the video content.\n",
        "\n",
        "5. **Gradio Interface:** The script creates a Gradio app with a user-friendly interface that includes input fields for the YouTube video URL, prompt text, text to translate, and target language selection. Output fields are provided for displaying extracted text, summarized text, similarity scores, missing points, and translated text. Buttons are included to trigger the extraction, analysis, and translation processes.\n",
        "\n",
        "\n",
        "In summary, this code provides a comprehensive tool for users to analyze video content by extracting subtitles, summarizing them, checking for similarity with a given prompt, and translating text into multiple languages. The use of Gradio allows for an interactive and visually appealing user experience, making it easy for users to engage with the functionalities offered by the application."
      ],
      "metadata": {
        "id": "lhpiEgnjXrCs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install the librarires"
      ],
      "metadata": {
        "id": "pgXthVzN9VWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio youtube-transcript-api transformers torch sentence-transformers wordcloud matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-7s0-U-xQrr",
        "outputId": "751551e3-8398-4ef8-c426-863aeacb5885"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.29.0)\n",
            "Requirement already satisfied: youtube-transcript-api in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.11/dist-packages (1.9.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.10.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2.4.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Io_4I0CSaA7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Similarity Analysis from Video - with Summarization"
      ],
      "metadata": {
        "id": "Mcb3e9OyaBhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound, VideoUnavailable\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import re\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Load the similarity model and summarization model once at the start\n",
        "similarity_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "summarization_model = pipeline(\"summarization\")\n",
        "\n",
        "# Function to extract subtitles from a YouTube video with error handling\n",
        "def extract_subtitles(video_url):\n",
        "    try:\n",
        "        video_id = video_url.split(\"v=\")[-1]\n",
        "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "        # Combine the text from the transcript\n",
        "        full_text = \" \".join([entry['text'] for entry in transcript])\n",
        "        return full_text\n",
        "    except NoTranscriptFound:\n",
        "        return \"Error: No transcript available for this video.\"\n",
        "    except VideoUnavailable:\n",
        "        return \"Error: The video is unavailable or does not have subtitles.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: An unexpected error occurred: {str(e)}\"\n",
        "\n",
        "# Function to save extracted text to a file\n",
        "def save_extracted_text(video_id, text):\n",
        "    with open(f\"{video_id}_transcript.txt\", \"w\") as f:\n",
        "        f.write(text)\n",
        "\n",
        "# Function to create a word cloud image\n",
        "def create_wordcloud(text, filename, title=None):\n",
        "    if not text.strip():  # Check if the text is empty\n",
        "        return None\n",
        "\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "\n",
        "    plt.figure(figsize=(18, 6))\n",
        "    plt.imshow(wordcloud, interpolation='bicubic')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Add title if provided\n",
        "    if title:\n",
        "        plt.title(title, fontsize=24, color='black')  # Customize title appearance as needed\n",
        "\n",
        "    plt.savefig(filename, format='png')\n",
        "    plt.close()\n",
        "    return filename\n",
        "\n",
        "# Function to summarize text\n",
        "def summarize_text(text):\n",
        "    if len(text) > 1024:  # Adjust the length limit as needed\n",
        "        text = text[:1024]  # Truncate to the first 1024 characters\n",
        "    summarized = summarization_model(text, max_length=150, min_length=30, do_sample=False)\n",
        "    return summarized[0]['summary_text']\n",
        "\n",
        "# Function to handle text extraction and update the output\n",
        "def extract_and_display_text(video_url):\n",
        "    extracted_text = extract_subtitles(video_url)\n",
        "    if \"Error\" in extracted_text:\n",
        "        return extracted_text, \"\", None, None  # Return error message and empty summary\n",
        "\n",
        "    # Create the word cloud for the extracted text with a title\n",
        "    extracted_wordcloud_path = create_wordcloud(extracted_text, 'extracted_wordcloud_sum.png', title='Extracted Text WordCloud')\n",
        "\n",
        "    # Summarize the extracted text\n",
        "    summarized_text = summarize_text(extracted_text)\n",
        "\n",
        "    # Create a word cloud for the summarized text\n",
        "    summarized_wordcloud_path = create_wordcloud(summarized_text, 'summarized_wordcloud_sum.png', title='Summarized Text WordCloud')\n",
        "\n",
        "    return extracted_text, summarized_text, extracted_wordcloud_path, summarized_wordcloud_path\n",
        "\n",
        "# Gradio interface\n",
        "def gradio_interface(prompt, video_url):\n",
        "    score, gaps, missing_wordcloud_path = analyze_text(prompt, video_url)\n",
        "    return score, gaps, missing_wordcloud_path\n",
        "\n",
        "# Create Gradio app\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"<h2 style='text-align: center;'>Text Similarity Analysis from Video - with Summarization </h2>\")\n",
        "\n",
        "    # Example video URLs\n",
        "    gr.Markdown(\"### Example YouTube Video URLs\")\n",
        "    gr.Markdown(\"- [DNA Structure and Replication](https://www.youtube.com/watch?v=8kK2zwjRV0M)\")\n",
        "    gr.Markdown(\"- [Startup Success](https://www.youtube.com/watch?v=0lJKucu6HJc&ab_channel=YCombinator)\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            video_url = gr.Textbox(label=\"YouTube Video URL\", placeholder=\"Enter the YouTube video URL here...\")\n",
        "            extracted_text_output = gr.Textbox(label=\"Extracted Text\", interactive=False, lines=10)\n",
        "            summarized_text_output = gr.Textbox(label=\"Summarized Text\", interactive=False, lines=5)  # New output for summarized text\n",
        "            extract_btn = gr.Button(\"Extract Text\")\n",
        "            extracted_wordcloud = gr.Image(label=\"Extracted Text Word Cloud\", interactive=False)\n",
        "            summarized_wordcloud = gr.Image(label=\"Summarized Text Word Cloud\", interactive=False)\n",
        "\n",
        "\n",
        "        with gr.Column():\n",
        "            prompt = gr.Textbox(label=\"Prompt Text\", placeholder=\"Enter your prompt text here...\")\n",
        "\n",
        "            similarity_output = gr.Textbox(label=\"Similarity Score\", interactive=False)\n",
        "            gaps_output = gr.Textbox(label=\"Missing Points\", interactive=False)\n",
        "\n",
        "            missing_wordcloud = gr.Image(label=\"Missing Points Word Cloud\", interactive=False)\n",
        "            submit_btn = gr.Button(\"Analyze\")\n",
        "\n",
        "    # Button click events\n",
        "    extract_btn.click(extract_and_display_text, inputs=video_url, outputs=[extracted_text_output, summarized_text_output, extracted_wordcloud, summarized_wordcloud])\n",
        "    submit_btn.click(gradio_interface, inputs=[prompt, video_url], outputs=[similarity_output, gaps_output, missing_wordcloud])\n",
        "\n",
        "    gr.Markdown(\"### Example Prompts\")\n",
        "    gr.Markdown(\"- Explain the structure of DNA and its significance in genetics.\")\n",
        "    gr.Markdown(\"- DNA sequencing is used in modern medicine\")\n",
        "    gr.Markdown(\"- DNA plays a weak role in the process of protein synthesis.\")\n",
        "    gr.Markdown(\"- DNA sequencing has major implications in modern medicine.\")\n",
        "    gr.Markdown(\"- How does DNA replication occur, and why is it important for cell division?\")\n",
        "    gr.Markdown(\"- What are the ethical considerations surrounding genetic engineering and DNA manipulation?\")\n",
        "\n",
        "# Launch the app\n",
        "app.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "0SpROiAAI_9-",
        "outputId": "51d5dffb-0793-4aad-b1d2-fe7124760eb2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9af22291332461dde7.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9af22291332461dde7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traduction from English to Arabic"
      ],
      "metadata": {
        "id": "lvwF9f_SRn6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound, VideoUnavailable\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import re\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Load the similarity model, summarization model, and translation model once at the start\n",
        "similarity_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "summarization_model = pipeline(\"summarization\")\n",
        "translation_model = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-ar\")  # English to Arabic translation model\n",
        "\n",
        "# Function to extract subtitles from a YouTube video with error handling\n",
        "def extract_subtitles(video_url):\n",
        "    try:\n",
        "        video_id = video_url.split(\"v=\")[-1]\n",
        "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "        # Combine the text from the transcript\n",
        "        full_text = \" \".join([entry['text'] for entry in transcript])\n",
        "        return full_text\n",
        "    except NoTranscriptFound:\n",
        "        return \"Error: No transcript available for this video.\"\n",
        "    except VideoUnavailable:\n",
        "        return \"Error: The video is unavailable or does not have subtitles.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: An unexpected error occurred: {str(e)}\"\n",
        "\n",
        "# Function to save extracted text to a file\n",
        "def save_extracted_text(video_id, text):\n",
        "    with open(f\"{video_id}_transcript.txt\", \"w\") as f:\n",
        "        f.write(text)\n",
        "\n",
        "# Function to create a word cloud image\n",
        "def create_wordcloud(text, filename, title=None):\n",
        "    if not text.strip():  # Check if the text is empty\n",
        "        return None\n",
        "\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "\n",
        "    plt.figure(figsize=(18, 6))\n",
        "    plt.imshow(wordcloud, interpolation='bicubic')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Add title if provided\n",
        "    if title:\n",
        "        plt.title(title, fontsize=24, color='black')  # Customize title appearance as needed\n",
        "\n",
        "    plt.savefig(filename, format='png')\n",
        "    plt.close()\n",
        "    return filename\n",
        "\n",
        "# Function to summarize text\n",
        "def summarize_text(text):\n",
        "    if len(text) > 1024:  # Adjust the length limit as needed\n",
        "        text = text[:1024]  # Truncate to the first 1024 characters\n",
        "    summarized = summarization_model(text, max_length=150, min_length=30, do_sample=False)\n",
        "    return summarized[0]['summary_text']\n",
        "\n",
        "# Function to translate text from English to Arabic\n",
        "def translate_text(text):\n",
        "    if not text.strip():\n",
        "        return \"\"\n",
        "    translated = translation_model(text)\n",
        "    return translated[0]['translation_text']\n",
        "\n",
        "# Function to handle text extraction and update the output\n",
        "def extract_and_display_text(video_url):\n",
        "    extracted_text = extract_subtitles(video_url)\n",
        "    if \"Error\" in extracted_text:\n",
        "        return extracted_text, \"\", None, None  # Return error message and empty summary\n",
        "\n",
        "    # Create the word cloud for the extracted text with a title\n",
        "    extracted_wordcloud_path = create_wordcloud(extracted_text, 'extracted_wordcloud_sum.png', title='Extracted Text WordCloud')\n",
        "\n",
        "    # Summarize the extracted text\n",
        "    summarized_text = summarize_text(extracted_text)\n",
        "\n",
        "    # Create a word cloud for the summarized text\n",
        "    summarized_wordcloud_path = create_wordcloud(summarized_text, 'summarized_wordcloud_sum.png', title='Summarized Text WordCloud')\n",
        "\n",
        "    return extracted_text, summarized_text, extracted_wordcloud_path, summarized_wordcloud_path\n",
        "\n",
        "# Gradio interface\n",
        "def gradio_interface(prompt, video_url):\n",
        "    score, gaps, missing_wordcloud_path = analyze_text(prompt, video_url)\n",
        "    return score, gaps, missing_wordcloud_path\n",
        "\n",
        "# Create Gradio app\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"<h2 style='text-align: center;'>Text Translation & Similarity Analysis from Video - with Summarization </h2>\")\n",
        "\n",
        "    # Example video URLs\n",
        "    gr.Markdown(\"### Example YouTube Video URLs\")\n",
        "    gr.Markdown(\"- [DNA Structure and Replication](https://www.youtube.com/watch?v=8kK2zwjRV0M)\")\n",
        "    gr.Markdown(\"- [Startup Success](https://www.youtube.com/watch?v=0lJKucu6HJc&ab_channel=YCombinator)\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            video_url = gr.Textbox(label=\"YouTube Video URL\", placeholder=\"Enter the YouTube video URL here...\")\n",
        "            extracted_text_output = gr.Textbox(label=\"Extracted Text\", interactive=False, lines=10)\n",
        "            summarized_text_output = gr.Textbox(label=\"Summarized Text\", interactive=False, lines=5)  # New output for summarized text\n",
        "            extracted_wordcloud = gr.Image(label=\"Extracted Text Word Cloud\", interactive=False)\n",
        "            summarized_wordcloud = gr.Image(label=\"Summarized Text Word Cloud\", interactive=False)\n",
        "            extract_btn = gr.Button(\"Extract Text\")\n",
        "\n",
        "        with gr.Column():\n",
        "            prompt = gr.Textbox(label=\"Prompt Text\", placeholder=\"Enter your prompt text here...\")\n",
        "            similarity_output = gr.Textbox(label=\"Similarity Score\", interactive=False)\n",
        "            gaps_output = gr.Textbox(label=\"Missing Points\", interactive=False)\n",
        "            missing_wordcloud = gr.Image(label=\"Missing Points Word Cloud\", interactive=False)\n",
        "            submit_btn = gr.Button(\"Analyze\")\n",
        "\n",
        "    with gr.Row():\n",
        "      with gr.Column():\n",
        "            translation_input = gr.Textbox(label=\"Text to Translate\", placeholder=\"Enter text in English here...\")\n",
        "            translate_btn = gr.Button(\"Translate\")\n",
        "      with gr.Column():\n",
        "            translation_output = gr.Textbox(label=\"Translated Text (Arabic)\", interactive=False)  # Output for translation\n",
        "\n",
        "\n",
        "    # Button click events\n",
        "\n",
        "    extract_btn.click(extract_and_display_text, inputs=video_url, outputs=[extracted_text_output, summarized_text_output, extracted_wordcloud, summarized_wordcloud])\n",
        "    submit_btn.click(gradio_interface, inputs=[prompt, video_url], outputs=[similarity_output, gaps_output, missing_wordcloud])\n",
        "    translate_btn.click(translate_text, inputs=translation_input, outputs=translation_output)\n",
        "\n",
        "\n",
        "    gr.Markdown(\"### Example Prompts\")\n",
        "    gr.Markdown(\"- Explain the structure of DNA and its significance in genetics.\")\n",
        "    gr.Markdown(\"- DNA sequencing is used in modern medicine\")\n",
        "    gr.Markdown(\"- DNA plays a weak role in the process of protein synthesis.\")\n",
        "    gr.Markdown(\"- DNA sequencing has major implications in modern medicine.\")\n",
        "    gr.Markdown(\"- How does DNA replication occur, and why is it important for cell division?\")\n",
        "    gr.Markdown(\"- What are the ethical considerations surrounding genetic engineering and DNA manipulation?\")\n",
        "\n",
        "# Launch the app\n",
        "app.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "x8P94za2ML6w",
        "outputId": "481503a8-633d-4463-b561-04e3aefe0a80"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6adccc3771ddf0fa69.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6adccc3771ddf0fa69.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hcesy-VROdX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4MbU0-XfRsCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traduction from English to multi-languages\n"
      ],
      "metadata": {
        "id": "OC66p2LDR02O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound, VideoUnavailable\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import re\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Load the similarity model, summarization model, and translation model once at the start\n",
        "similarity_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "summarization_model = pipeline(\"summarization\")\n",
        "\n",
        "# Define a dictionary for translation models\n",
        "translation_models = {\n",
        "    \"Arabic\": \"Helsinki-NLP/opus-mt-en-ar\",\n",
        "    \"Spanish\": \"Helsinki-NLP/opus-mt-en-es\",\n",
        "    \"French\": \"Helsinki-NLP/opus-mt-en-fr\",\n",
        "    \"German\": \"Helsinki-NLP/opus-mt-en-de\",\n",
        "    \"Chinese\": \"Helsinki-NLP/opus-mt-en-zh\",\n",
        "}\n",
        "\n",
        "# Load translation models\n",
        "translation_pipelines = {lang: pipeline(\"translation\", model=model) for lang, model in translation_models.items()}\n",
        "\n",
        "# Function to extract subtitles from a YouTube video with error handling\n",
        "def extract_subtitles(video_url):\n",
        "    try:\n",
        "        video_id = video_url.split(\"v=\")[-1]\n",
        "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "        # Combine the text from the transcript\n",
        "        full_text = \" \".join([entry['text'] for entry in transcript])\n",
        "        return full_text\n",
        "    except NoTranscriptFound:\n",
        "        return \"Error: No transcript available for this video.\"\n",
        "    except VideoUnavailable:\n",
        "        return \"Error: The video is unavailable or does not have subtitles.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: An unexpected error occurred: {str(e)}\"\n",
        "\n",
        "# Function to save extracted text to a file\n",
        "def save_extracted_text(video_id, text):\n",
        "    with open(f\"{video_id}_transcript.txt\", \"w\") as f:\n",
        "        f.write(text)\n",
        "\n",
        "# Function to create a word cloud image\n",
        "def create_wordcloud(text, filename, title=None):\n",
        "    if not text.strip():  # Check if the text is empty\n",
        "        return None\n",
        "\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "\n",
        "    plt.figure(figsize=(18, 6))\n",
        "    plt.imshow(wordcloud, interpolation='bicubic')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Add title if provided\n",
        "    if title:\n",
        "        plt.title(title, fontsize=24, color='black')  # Customize title appearance as needed\n",
        "\n",
        "    plt.savefig(filename, format='png')\n",
        "    plt.close()\n",
        "    return filename\n",
        "\n",
        "# Function to summarize text\n",
        "def summarize_text(text):\n",
        "    if len(text) > 1024:  # Adjust the length limit as needed\n",
        "        text = text[:1024]  # Truncate to the first 1024 characters\n",
        "    summarized = summarization_model(text, max_length=150, min_length=30, do_sample=False)\n",
        "    return summarized[0]['summary_text']\n",
        "\n",
        "# Function to translate text from English to the selected language\n",
        "def translate_text(text, target_language):\n",
        "    if not text.strip() or target_language not in translation_pipelines:\n",
        "        return \"\"\n",
        "\n",
        "    # Split the text into chunks of 512 characters\n",
        "    chunk_size = 512\n",
        "    chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "\n",
        "    # Translate each chunk and join the results\n",
        "    translated_chunks = []\n",
        "    for chunk in chunks:\n",
        "        translated = translation_pipelines[target_language](chunk)\n",
        "        translated_chunks.append(translated[0]['translation_text'])\n",
        "\n",
        "    return \" \".join(translated_chunks)\n",
        "\n",
        "# Function to handle text extraction and update the output\n",
        "def extract_and_display_text(video_url):\n",
        "    extracted_text = extract_subtitles(video_url)\n",
        "    if \"Error\" in extracted_text:\n",
        "        return extracted_text, \"\", None, None  # Return error message and empty summary\n",
        "\n",
        "    # Create the word cloud for the extracted text with a title\n",
        "    extracted_wordcloud_path = create_wordcloud(extracted_text, 'extracted_wordcloud_sum.png', title='Extracted Text WordCloud')\n",
        "\n",
        "    # Summarize the extracted text\n",
        "    summarized_text = summarize_text(extracted_text)\n",
        "\n",
        "    # Create a word cloud for the summarized text\n",
        "    summarized_wordcloud_path = create_wordcloud(summarized_text, 'summarized_wordcloud_sum.png', title='Summarized Text WordCloud')\n",
        "\n",
        "    return extracted_text, summarized_text, extracted_wordcloud_path, summarized_wordcloud_path\n",
        "\n",
        "# Gradio interface\n",
        "def gradio_interface(prompt, video_url):\n",
        "    score, gaps, missing_wordcloud_path = analyze_text(prompt, video_url)\n",
        "    return score, gaps, missing_wordcloud_path\n",
        "\n",
        "# Create Gradio app\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"<h2 style='text-align: center;'>Text translation & Similarity Analysis from Video - with Summarization </h2>\")\n",
        "\n",
        "    # Example video URLs\n",
        "    gr.Markdown(\"### Example YouTube Video URLs\")\n",
        "    gr.Markdown(\"- [DNA Structure and Replication](https://www.youtube.com/watch?v=8kK2zwjRV0M)\")\n",
        "    gr.Markdown(\"- [Startup Success](https://www.youtube.com/watch?v=0lJKucu6HJc&ab_channel=YCombinator)\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            video_url = gr.Textbox(label=\"YouTube Video URL\", placeholder=\"Enter the YouTube video URL here...\")\n",
        "            extracted_text_output = gr.Textbox(label=\"Extracted Text\", interactive=False, lines=10)\n",
        "            summarized_text_output = gr.Textbox(label=\"Summarized Text\", interactive=False, lines=5)  # New output for summarized text\n",
        "            extract_btn = gr.Button(\"Extract Text\")\n",
        "            extracted_wordcloud = gr.Image(label=\"Extracted Text Word Cloud\", interactive=False)\n",
        "            summarized_wordcloud = gr.Image(label=\"Summarized Text Word Cloud\", interactive=False)\n",
        "\n",
        "\n",
        "        with gr.Column():\n",
        "            prompt = gr.Textbox(label=\"Prompt Text\", placeholder=\"Enter your prompt text here...\")\n",
        "            similarity_output = gr.Textbox(label=\"Similarity Score\", interactive=False)\n",
        "            gaps_output = gr.Textbox(label=\"Missing Points\", interactive=False)\n",
        "            missing_wordcloud = gr.Image(label=\"Missing Points Word Cloud\", interactive=False)\n",
        "            submit_btn = gr.Button(\"Analyze\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            translation_input = gr.Textbox(label=\"Text to Translate\", placeholder=\"Enter text in English here...\")\n",
        "            target_language = gr.Dropdown(label=\"Select Target Language\", choices=list(translation_models.keys()), value=\"Arabic\")\n",
        "            translate_btn = gr.Button(\"Translate\")\n",
        "        with gr.Column():\n",
        "            translation_output = gr.Textbox(label=\"Translated Text\", interactive=False)  # Output for translation\n",
        "\n",
        "    # Button click events\n",
        "    extract_btn.click(extract_and_display_text, inputs=video_url, outputs=[extracted_text_output, summarized_text_output, extracted_wordcloud, summarized_wordcloud])\n",
        "    submit_btn.click(gradio_interface, inputs=[prompt, video_url], outputs=[similarity_output, gaps_output, missing_wordcloud])\n",
        "    translate_btn.click(translate_text, inputs=[translation_input, target_language], outputs=translation_output)\n",
        "\n",
        "    gr.Markdown(\"### Example Prompts\")\n",
        "    gr.Markdown(\"- Explain the structure of DNA and its significance in genetics.\")\n",
        "    gr.Markdown(\"- DNA sequencing is used in modern medicine\")\n",
        "    gr.Markdown(\"- DNA plays a weak role in the process of protein synthesis.\")\n",
        "    gr.Markdown(\"- DNA sequencing has major implications in modern medicine.\")\n",
        "    gr.Markdown(\"- How does DNA replication occur, and why is it important for cell division?\")\n",
        "    gr.Markdown(\"- What are the ethical considerations surrounding genetic engineering and DNA manipulation?\")\n",
        "\n",
        "# Launch the app\n",
        "app.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        },
        "id": "ATP6t1OuR3fE",
        "outputId": "c1ce9eb8-bdef-489e-fb5a-d461c00eb0f8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5e59cbbced35fd7505.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5e59cbbced35fd7505.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "izGMbn_HSKQl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}