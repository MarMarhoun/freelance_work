{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNYKq8zYSin1Wdr6W4qxcK5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e330b1114af24f2c9bae0b921736ef86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7f4ea1e90644c9c84497b37213ac44a",
              "IPY_MODEL_a196962b92d941d4bc18a8ecf51115c0",
              "IPY_MODEL_5b4788172d43475ea85bf64f1718eabe"
            ],
            "layout": "IPY_MODEL_2fb0d959156d4566ad35cbcb31621d7e"
          }
        },
        "a7f4ea1e90644c9c84497b37213ac44a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2333881312194bd493e90c568827ae85",
            "placeholder": "​",
            "style": "IPY_MODEL_f16fbc1b8aea46bba26325fb03f0609f",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "a196962b92d941d4bc18a8ecf51115c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da93cb71f70e4b7ba396bfd480fb165a",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e642ae445cf48a5b36dbfdead186b15",
            "value": 7
          }
        },
        "5b4788172d43475ea85bf64f1718eabe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd9b24edd0a547e38599e42aa8115f1d",
            "placeholder": "​",
            "style": "IPY_MODEL_14f5f3b392ec4559bbd21a27472dfcad",
            "value": " 7/7 [01:03&lt;00:00, 11.08s/it]"
          }
        },
        "2fb0d959156d4566ad35cbcb31621d7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2333881312194bd493e90c568827ae85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f16fbc1b8aea46bba26325fb03f0609f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da93cb71f70e4b7ba396bfd480fb165a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e642ae445cf48a5b36dbfdead186b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd9b24edd0a547e38599e42aa8115f1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14f5f3b392ec4559bbd21a27472dfcad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarMarhoun/freelance_work/blob/main/side_projects/NLP_projs/LLMs_with_Gradio/llm_with_gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J50CRlDAWSk1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nP1ozHsSBXA"
      },
      "source": [
        "# AI web app using Gradio\n",
        "\n",
        "## Project description:\n",
        "\n",
        "In this notebook, I will try to create a web app using [Gradio](https://www.gradio.app/).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj0fP8LzThhF"
      },
      "source": [
        "> ## - Package installation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgycac6gi0zb",
        "outputId": "3684573b-6e0e-4efa-98fd-55c1f465da69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHiRU8TiOBtu",
        "outputId": "45bd1f00-c9e2-4390-86ff-ce6a26d82b23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.7.1-py3-none-any.whl (16.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.7.0 (from gradio)\n",
            "  Downloading gradio_client-0.7.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.7/302.7 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.19.4)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Collecting pydantic>=2.0 (from gradio)\n",
            "  Downloading pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.31.0)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.7.0->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.7.0->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (3.13.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->gradio)\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Collecting pydantic-core==2.14.5 (from pydantic>=2.0->gradio)\n",
            "  Downloading pydantic_core-2.14.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions~=4.0 (from gradio)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2023.7.22)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (3.7.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore==1.* (from httpx->gradio)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.11.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.31.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.13.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=00ad264a817c9e82f9d45cbc0b5f3ac2fd9f8fe5fc4cd7bcb07e48d55b869d17\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, typing-extensions, tomlkit, shellingham, semantic-version, python-multipart, orjson, h11, colorama, annotated-types, aiofiles, uvicorn, starlette, pydantic-core, httpcore, pydantic, httpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.13\n",
            "    Uninstalling pydantic-1.10.13:\n",
            "      Successfully uninstalled pydantic-1.10.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 annotated-types-0.6.0 colorama-0.4.6 fastapi-0.104.1 ffmpy-0.3.1 gradio-4.7.1 gradio-client-0.7.0 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 orjson-3.9.10 pydantic-2.5.2 pydantic-core-2.14.5 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.27.0 tomlkit-0.12.0 typing-extensions-4.8.0 uvicorn-0.24.0.post1 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDQw3gSlQZUp",
        "outputId": "9af1bafc-b986-4cf1-ddb4-770b28286a33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e6KFcgYk-zq",
        "outputId": "053fc076-d230-4efa-f426-5bcf3f0ab580"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/261.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/261.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.24.1\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rRvrM8WixYn",
        "outputId": "14271349-ed3d-4bff-a308-cc447acd6939"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.3.1\n",
            "Collecting diffusers\n",
            "  Downloading diffusers-0.23.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.24.1)\n",
            "Collecting peft\n",
            "  Downloading peft-0.6.2-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.19.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (6.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.23.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Downloading diffusers-0.23.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.6.2-py3-none-any.whl (174 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.7/174.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: diffusers, peft\n",
            "Successfully installed diffusers-0.23.1 peft-0.6.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install --upgrade diffusers transformers accelerate peft\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxpQowM7UYWo",
        "outputId": "53def4d0-949d-4936-9393-9c88cde1d6a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.8.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2023.7.22)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I68V1aqx5Af",
        "outputId": "7f6d929d-13c8-439f-d4b6-55e8c0e34adf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting diffusers\n",
            "  Downloading diffusers-0.23.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.19.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (6.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.23.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (4.8.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (23.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2023.7.22)\n",
            "Installing collected packages: diffusers\n",
            "Successfully installed diffusers-0.23.1\n"
          ]
        }
      ],
      "source": [
        "!pip install diffusers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## - Import the necessary libraries:"
      ],
      "metadata": {
        "id": "C4Fa50O9nMiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import base64\n",
        "from PIL import Image\n",
        "from IPython.display import Image, display #, HTML\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "from pathlib import Path\n",
        "from diffusers import DiffusionPipeline\n",
        "from transformers import pipeline, AutoTokenizer, TFAutoModelForQuestionAnswering\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "path = '/content/a.env'\n",
        "dotenv_path = Path(path)\n",
        "_ =load_dotenv(dotenv_path=dotenv_path) # read local .env file\n",
        "#_ = load_dotenv(find_dotenv())\n",
        "hf_api_key = os.environ['HF_API_KEY']"
      ],
      "metadata": {
        "id": "BD1oLbBDnXK3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiCDbLsxO64R"
      },
      "source": [
        "> # - NLP tasks with a simple interface"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## Helper functions"
      ],
      "metadata": {
        "id": "Y99LobSrgXkV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LTtc8XQiTl9"
      },
      "source": [
        "> ## - Building a text summarization app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MPrur7rIiJm8"
      },
      "outputs": [],
      "source": [
        "## ref: https://learn.deeplearning.ai/huggingface-gradio/lesson/2/nlp-tasks-interface\n",
        "# Use a pipeline as a high-level helper\n",
        "\n",
        "get_completion = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
        "\n",
        "def summarize(input):\n",
        "    output = get_completion(input)\n",
        "    return output[0]['summary_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2srgjvIiwVp",
        "outputId": "d4601fdf-35ac-4543-dbc9-9c82e6e910e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': ' The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building in Paris . It is the second tallest free-standing structure in France after the Millau Viaduct . It was the first structure in the world to reach a height of 300 metres . The Eiffel Tower is now taller than the Chrysler Building in New York City by 5.2 metres (17 ft)'}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "text = ('''The tower is 324 metres (1,063 ft) tall, about the same height\n",
        "        as an 81-storey building, and the tallest structure in Paris.\n",
        "        Its base is square, measuring 125 metres (410 ft) on each side.\n",
        "        During its construction, the Eiffel Tower surpassed the Washington\n",
        "        Monument to become the tallest man-made structure in the world,\n",
        "        a title it held for 41 years until the Chrysler Building\n",
        "        in New York City was finished in 1930. It was the first structure\n",
        "        to reach a height of 300 metres. Due to the addition of a broadcasting\n",
        "        aerial at the top of the tower in 1957, it is now taller than the\n",
        "        Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the\n",
        "        Eiffel Tower is the second tallest free-standing structure in France\n",
        "        after the Millau Viaduct.''')\n",
        "\n",
        "get_completion(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "J-HGCc35m2nt",
        "outputId": "e2c34e57-c1d0-4c06-8346-8ce1f3202df7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://4d062bf05deef80870.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4d062bf05deef80870.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "gr.close_all()\n",
        "demo = gr.Interface(fn=summarize, inputs=\"text\", outputs=\"text\")\n",
        "demo.launch()\n",
        "\n",
        "text_ex = \"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris.  Its base is square, measuring 125 metres (410 ft) on each side.  During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure to reach a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "li9PauPMPMMe",
        "outputId": "0224718d-5964-4030-d8a2-dea0f166ff4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://b26d8d892eaed3da26.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b26d8d892eaed3da26.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#\n",
        "\n",
        "def summarize(input):\n",
        "    output = get_completion(input)\n",
        "    return output[0]['summary_text']\n",
        "\n",
        "gr.close_all()\n",
        "demo2 = gr.Interface(fn=summarize,\n",
        "                    inputs=[gr.Textbox(label=\"Text to summarize\", lines=6)],\n",
        "                    outputs=[gr.Textbox(label=\"Result\", lines=3)],\n",
        "                    title=\"Text summarization with distilbart-cnn\",\n",
        "                    description=\"Summarize any text using the `shleifer/distilbart-cnn-12-6` model under the hood!\"\n",
        "                   )\n",
        "demo2.launch(share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfIivYTgAuKx"
      },
      "source": [
        "> ## Building a Named Entity Recognition app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2zcTANOA9sW",
        "outputId": "4dbc5a92-055a-4bd7-81d0-6b5a6f0e6838"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ],
      "source": [
        "# from transformers import pipeline\n",
        "\n",
        "get_completion1 = pipeline(\"ner\", model=\"dslim/bert-base-NER\")\n",
        "\n",
        "def ner(input):\n",
        "  output = get_completion(input)\n",
        "  return {\"text\": input, \"entities\": output}\n",
        "\n",
        "\n",
        "gr.close_all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khyGG72DP0e6"
      },
      "outputs": [],
      "source": [
        "#API_URL = os.environ['HF_API_NER_BASE'] #NER endpoint\n",
        "text = \"My name is Andrew, I'm building DeepLearningAI and I live in California\"\n",
        "get_completion1(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "A--fPCugWb-k",
        "outputId": "9bd7a3c8-ecca-4aba-a1bb-31282ef8cbcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://3f569fd3c1e732bad4.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3f569fd3c1e732bad4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Adding a helper function to merge tokens\n",
        "\n",
        "def merge_tokens(tokens):\n",
        "    merged_tokens = []\n",
        "    for token in tokens:\n",
        "        if merged_tokens and token['entity'].startswith('I-') and merged_tokens[-1]['entity'].endswith(token['entity'][2:]):\n",
        "            # If current token continues the entity of the last one, merge them\n",
        "            last_token = merged_tokens[-1]\n",
        "            last_token['word'] += token['word'].replace('##', '')\n",
        "            last_token['end'] = token['end']\n",
        "            last_token['score'] = (last_token['score'] + token['score']) / 2\n",
        "        else:\n",
        "            # Otherwise, add the token to the list\n",
        "            merged_tokens.append(token)\n",
        "\n",
        "    return merged_tokens\n",
        "\n",
        "def ner3(input):\n",
        "    output = get_completion(input)#, parameters=None, ENDPOINT_URL=API_URL)\n",
        "    merged_tokens = merge_tokens(output)\n",
        "    return {\"text\": input, \"entities\": merged_tokens}\n",
        "\n",
        "\n",
        "\n",
        "gr.close_all()\n",
        "\n",
        "with gr.Blocks() as demo3:\n",
        "  gr.Interface(fn=ner3,\n",
        "               inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)],\n",
        "               outputs=[gr.HighlightedText(label=\"Text with entities\")],\n",
        "               title=\"NER with dslim/bert-base-NER\",\n",
        "               description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n",
        "               allow_flagging=\"never\",\n",
        "               examples=[\"My name is Andrew, I'm building DeeplearningAI and I live in California\", \"My name is Poli, I live in Vienna and work at HuggingFace\"])\n",
        "  #txt = gr.Textbox(label=\"Input\", lines=2)\n",
        "  #txt_2 = gr.Textbox(value=\"\", label=\"Output\")\n",
        "  #btn = gr.Button(value=\"Submit\")\n",
        "  #btn.click(combine, inputs=[txt], outputs=[txt_2])\n",
        "\n",
        "  #gr.Markdown(\"## Model Examples\")\n",
        "\n",
        "\n",
        "\n",
        "demo3.launch(share=True) #, server_port=int(os.environ['PORT4']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSldFG9HYext"
      },
      "source": [
        "> ## QA machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "DRrqcQLPU8Lc",
        "outputId": "657f8337-0254-4d8c-b36b-baa6c34c5006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/blocks.py:528: UserWarning: Cannot load peach. Caught Exception: The space peach does not exist\n",
            "  warnings.warn(f\"Cannot load {theme}. Caught Exception: {str(e)}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://e88f7e988f53313a52.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e88f7e988f53313a52.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "title = 'Question Answering demo with transformers and gradio'\n",
        "\n",
        "context = \"The Amazon rainforest (Portuguese: Floresta Amazônica or Amazônia; Spanish: Selva Amazónica, Amazonía or usually Amazonia; French: Forêt amazonienne; Dutch: Amazoneregenwoud), also known in English as Amazonia or the Amazon Jungle, is a moist broadleaf forest that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 square kilometres (2,700,000 sq mi), of which 5,500,000 square kilometres (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations. The majority of the forest is contained within Brazil, with 60% of the rainforest, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Venezuela, Ecuador, Bolivia, Guyana, Suriname, and French Guiana. States or departments in four nations contain 'Amazonas' in their names. The Amazon represents over half of the planet's remaining rainforests, and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees divided into 16,000 species.\"\n",
        "\n",
        "question = \"Which name is also used to describe the Amazon rainforest in English?\"\n",
        "\n",
        "\n",
        "question_answerer = pipeline(\"question-answering\")\n",
        "\n",
        "\n",
        "interface = gr.Interface.from_pipeline(question_answerer,\n",
        "    title = title,\n",
        "    theme = \"peach\",\n",
        "    examples = [[context, question]]).launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yk-bnnGEWH_7",
        "outputId": "3d2c8a5a-22ae-4a80-bda8-626bae569f8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForQuestionAnswering.\n",
            "\n",
            "All the weights of TFBertForQuestionAnswering were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "model = TFAutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\",return_dict=False)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
        "nlp = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WIQhLfu4WRmZ"
      },
      "outputs": [],
      "source": [
        "# creating the function\n",
        "def func(context, question):\n",
        "  result = nlp(question = question, context=context)\n",
        "  return result['answer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TDSxh7mWUuT",
        "outputId": "aa79046b-74b0-41fc-df32-eddc8b8f1e1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n",
            "Closing server running on port: 7861\n",
            "Closing server running on port: 7860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/blocks.py:528: UserWarning: Cannot load dark-grass. Caught Exception: The space dark-grass does not exist\n",
            "  warnings.warn(f\"Cannot load {theme}. Caught Exception: {str(e)}\")\n"
          ]
        }
      ],
      "source": [
        "# creating the interface\n",
        "gr.close_all()\n",
        "app = gr.Interface(fn=func, inputs = ['textbox', 'text'], outputs = 'textbox', title = 'Question Answering bot', theme = 'dark-grass', examples = [[context, question]],description = 'Input context and question, then get answers!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "3fDXkbCmWdQF",
        "outputId": "e25003f0-0075-4770-e497-791a91a9ecca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://340ed20cb91d65bbd0.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://340ed20cb91d65bbd0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# launching the app\n",
        "\n",
        "app.launch()#inline=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCGFD5hGWefy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPDFno7aWel_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgeYsrFfPtrG"
      },
      "source": [
        "> # - CV tasks with a simple interface"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## Helper functions"
      ],
      "metadata": {
        "id": "IrNoYcpshVl8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2Rzy8f2waDY"
      },
      "source": [
        "> ## Image Captioning App  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "snCbU83zPuE4"
      },
      "outputs": [],
      "source": [
        "# Helper functions\n",
        "import requests, json\n",
        "\n",
        "#Image-to-text endpoint\n",
        "def get_compl_ic(inputs, parameters=None, ENDPOINT_URL=os.environ['HF_API_ITT_BASE']):\n",
        "    headers = {\n",
        "      \"Authorization\": f\"Bearer {hf_api_key}\",\n",
        "      \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    data = { \"inputs\": inputs }\n",
        "    if parameters is not None:\n",
        "        data.update({\"parameters\": parameters})\n",
        "    response = requests.request(\"POST\",\n",
        "                                ENDPOINT_URL,\n",
        "                                headers=headers,\n",
        "                                data=json.dumps(data))\n",
        "    return json.loads(response.content.decode(\"utf-8\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ITeTbt-vP1G_"
      },
      "outputs": [],
      "source": [
        "#\n",
        "\n",
        "get_compl_ic = pipeline(\"image-to-text\",model=\"Salesforce/blip-image-captioning-base\")\n",
        "\n",
        "def summarize(input):\n",
        "    output = get_compl_ic(input)\n",
        "    return output[0]['generated_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "Epuo3sp8P3ez",
        "outputId": "59f28520-50f9-483d-a3c5-adb1a7383d3e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<img src=\"https://free-images.com/sm/9596/dog_animal_greyhound_983023.jpg\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'generated_text': 'a dog wearing a santa hat and a red scarf'}]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_url = \"https://free-images.com/sm/9596/dog_animal_greyhound_983023.jpg\"\n",
        "display(IPython.display.Image(url=image_url))\n",
        "get_compl_ic(image_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "hnkVQr9LP7FO",
        "outputId": "e0c20ea6-0095-4647-f7d0-c47280aebee0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7861\n",
            "Closing server running on port: 7863\n",
            "Closing server running on port: 7860\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://5743d2edbae260a445.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5743d2edbae260a445.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def image_to_base64_str(pil_image):\n",
        "    byte_arr = io.BytesIO()\n",
        "    pil_image.save(byte_arr, format='PNG')\n",
        "    byte_arr = byte_arr.getvalue()\n",
        "    return str(base64.b64encode(byte_arr).decode('utf-8'))\n",
        "\n",
        "def captioner(image):\n",
        "    base64_image = image_to_base64_str(image)\n",
        "    result = get_compl_ic(base64_image)\n",
        "    return result[0]['generated_text']\n",
        "\n",
        "gr.close_all()\n",
        "demo = gr.Interface(fn=captioner,\n",
        "                    inputs=[gr.Image(label=\"Upload image\", type=\"pil\")],\n",
        "                    outputs=[gr.Textbox(label=\"Caption\")],\n",
        "                    title=\"Image Captioning with BLIP\",\n",
        "                    description=\"Caption any image using the BLIP model\",\n",
        "                    allow_flagging=\"never\",\n",
        "                    examples=[\"christmas_dog.jpeg\", \"bird_flight.jpeg\", \"cow.jpeg\"])\n",
        "\n",
        "demo.launch(share=True)#, server_port=int(os.environ['PORT1']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d_fpPAzwkCO"
      },
      "source": [
        "> ## Image Generation App"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "d4wM-dkVwqzK"
      },
      "outputs": [],
      "source": [
        "# Helper function\n",
        "import requests, json\n",
        "\n",
        "#Text-to-image endpoint\n",
        "def get_comp_ig(inputs, parameters=None, ENDPOINT_URL=os.environ['HF_API_TTI_BASE']):\n",
        "    headers = {\n",
        "      \"Authorization\": f\"Bearer {hf_api_key}\",\n",
        "      \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    data = { \"inputs\": inputs }\n",
        "    if parameters is not None:\n",
        "        data.update({\"parameters\": parameters})\n",
        "    response = requests.request(\"POST\",\n",
        "                                ENDPOINT_URL,\n",
        "                                headers=headers,\n",
        "                                data=json.dumps(data))\n",
        "    return json.loads(response.content.decode(\"utf-8\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "e330b1114af24f2c9bae0b921736ef86",
            "a7f4ea1e90644c9c84497b37213ac44a",
            "a196962b92d941d4bc18a8ecf51115c0",
            "5b4788172d43475ea85bf64f1718eabe",
            "2fb0d959156d4566ad35cbcb31621d7e",
            "2333881312194bd493e90c568827ae85",
            "f16fbc1b8aea46bba26325fb03f0609f",
            "da93cb71f70e4b7ba396bfd480fb165a",
            "6e642ae445cf48a5b36dbfdead186b15",
            "bd9b24edd0a547e38599e42aa8115f1d",
            "14f5f3b392ec4559bbd21a27472dfcad"
          ]
        },
        "id": "ZFCMuIs6xiRH",
        "outputId": "d0a10a61-ff7d-468c-d0db-cdbf570b2765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
            "```\n",
            "pip install accelerate\n",
            "```\n",
            ".\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e330b1114af24f2c9bae0b921736ef86"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "\n",
        "model = \"runwayml/stable-diffusion-v1-5\" #\"stabilityai/stable-diffusion-xl-base-1.0\" #\n",
        "pipe_im = DiffusionPipeline.from_pretrained(model)\n",
        "\n",
        "def get_comp_ig(prompt):\n",
        "    return pipe_im(prompt).images[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"a dog in a park\"\n",
        "\n",
        "result = get_comp_ig(prompt)\n",
        "result\n",
        "\n",
        "\n",
        "\n",
        "IPython.display.HTML(f'<img src=\"data:image/png;base64,{result}\" />')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b5167eb32a784127bcd5c55dee160cb6",
            "90167f13d95342698a7610b69030c217",
            "ab52e03c33814d43904a9cfd5ded7e43",
            "28586ce553864a1f92551edceef59bbf",
            "c1579ee808c541c9aeee38c2d2e44948",
            "04ddaf760a1745469cff16573665fd65",
            "5ab3218418c946018a2d5a5113fdb4bc",
            "41e6a49b685d41c2909cf03bc5eae842",
            "e683ea88b6fa4b3b8bf580d23eeaed31",
            "4bad7d4a519b45a3b7803855b880eea7",
            "d3207252f75c4a75871d0a4f31536acf"
          ]
        },
        "id": "9wL4yDbfvsQU",
        "outputId": "1fbc618f-dd64-437f-8bb9-ab5125dde662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5167eb32a784127bcd5c55dee160cb6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt = \"pikachu\"\n",
        "result = get_comp_ig(prompt).images[0]\n",
        "result\n"
      ],
      "metadata": {
        "id": "_pcoxddBW3Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pipe = StableDiffusionPipeline.from_pretrained(model_id, revision=branch_name, torch_dtype=torch.float16)\n",
        "#pipe = pipe.to(\"cuda\")\n",
        "\n",
        "prompt = \"pikachu\"\n",
        "image = get_comp_ig(prompt).images[0]\n",
        "image\n",
        "#image.save(\"./pikachu.png\")\n"
      ],
      "metadata": {
        "id": "KjG5tmTmKh_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69,
          "referenced_widgets": [
            "24c02befcbba47c2a766ef9c64f7249a",
            "346ea38fa7344ad2be33858dcee5739c",
            "688b1aa8f75244128c7f931dde5b8dea",
            "d8d916ff76f349c29078ec14da06cf69",
            "40a69edd03d6497897861134f7b03208",
            "e6ef09390dbc45ce931497906f46ebab",
            "e9d53f64a363499b825bfe306561876f",
            "63a0e9b97ee0408aab5f03a9fb41e6b5",
            "c6b6328a66ae4bf3b8148250784230c3",
            "d09da3928be64df5b4f5c203d751d52e",
            "1bbf98e2d9054c91b3188d210f8c822b"
          ]
        },
        "id": "Iara_xCkyLKc",
        "outputId": "367911b8-c5bd-49dc-94bc-e342c9849007"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24c02befcbba47c2a766ef9c64f7249a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<img src=\"data:image/png;base64,<PIL.Image.Image image mode=RGB size=512x512 at 0x7922C79BABF0>\" />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"a dog in a park\"\n",
        "\n",
        "result = get_comp_ig(prompt)\n",
        "result\n",
        "\n",
        "\n",
        "IPython.display.HTML(f'<img src=\"data:image/png;base64,{result}\" />')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "n1Jlt5cIy3DN",
        "outputId": "04951f6a-323b-458f-9834-cd1bfc505f09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7861\n",
            "Closing server running on port: 7860\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://6684c436b0d9207479.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6684c436b0d9207479.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "#A helper function to convert the PIL image to base64\n",
        "#so you can send it to the API\n",
        "def base64_to_pil(img_base64):\n",
        "    base64_decoded = base64.b64decode(img_base64)\n",
        "    byte_stream = io.BytesIO(base64_decoded)\n",
        "    pil_image = Image.open(byte_stream)\n",
        "    return pil_image\n",
        "\n",
        "def generate1(prompt):\n",
        "    output = get_comp_ig(prompt)\n",
        "    result_image = base64_to_pil(output)\n",
        "    return result_image\n",
        "\n",
        "gr.close_all()\n",
        "demo = gr.Interface(fn=generate1,\n",
        "                    inputs=[gr.Textbox(label=\"Your prompt\")],\n",
        "                    outputs=[gr.Image(label=\"Result\")],\n",
        "                    title=\"Image Generation with Stable Diffusion\",\n",
        "                    description=\"Generate any image with Stable Diffusion\",\n",
        "                    allow_flagging=\"never\",\n",
        "                    examples=[\"the spirit of a tamagotchi wandering in the city of Vienna\",\"a mecha robot in a favela\"])\n",
        "\n",
        "demo.launch(share=True) #, server_port=int(os.environ['PORT1']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZvjgjCOReuf"
      },
      "outputs": [],
      "source": [
        "demo.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WTEIqDFSmAF"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "#A helper function to convert the PIL image to base64\n",
        "# so you can send it to the API\n",
        "def base64_to_pil(img_base64):\n",
        "    base64_decoded = base64.b64decode(img_base64)\n",
        "    byte_stream = io.BytesIO(base64_decoded)\n",
        "    pil_image = Image.open(byte_stream)\n",
        "    return pil_image\n",
        "\n",
        "def generate(prompt, negative_prompt, steps, guidance, width, height):\n",
        "    params = {\n",
        "        \"negative_prompt\": negative_prompt,\n",
        "        \"num_inference_steps\": steps,\n",
        "        \"guidance_scale\": guidance,\n",
        "        \"width\": width,\n",
        "        \"height\": height\n",
        "    }\n",
        "\n",
        "    output = get_completion(prompt, params)\n",
        "    pil_image = base64_to_pil(output)\n",
        "    return pil_image\n",
        "\n",
        "gr.close_all()\n",
        "demo = gr.Interface(fn=generate,\n",
        "                    inputs=[\n",
        "                        gr.Textbox(label=\"Your prompt\"),\n",
        "                        gr.Textbox(label=\"Negative prompt\"),\n",
        "                        gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
        "                                 info=\"In how many steps will the denoiser denoise the image?\"),\n",
        "                        gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
        "                                  info=\"Controls how much the text prompt influences the result\"),\n",
        "                        gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512),\n",
        "                        gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512),\n",
        "                    ],\n",
        "                    outputs=[gr.Image(label=\"Result\")],\n",
        "                    title=\"Image Generation with Stable Diffusion\",\n",
        "                    description=\"Generate any image with Stable Diffusion\",\n",
        "                    allow_flagging=\"never\"\n",
        "                    )\n",
        "\n",
        "demo.launch(share=True, server_port=int(os.environ['PORT2']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eAZAFtOSmTO"
      },
      "outputs": [],
      "source": [
        "demo.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eL7HOUF-Smps"
      },
      "outputs": [],
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n",
        "    prompt = gr.Textbox(label=\"Your prompt\")\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n",
        "            steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
        "                      info=\"In many steps will the denoiser denoise the image?\")\n",
        "            guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
        "                      info=\"Controls how much the text prompt influences the result\")\n",
        "            width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n",
        "            height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n",
        "            btn = gr.Button(\"Submit\")\n",
        "        with gr.Column():\n",
        "            output = gr.Image(label=\"Result\")\n",
        "\n",
        "    btn.click(fn=generate, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\n",
        "gr.close_all()\n",
        "demo.launch(share=True, server_port=int(os.environ['PORT3']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoUEDX4pSm9b"
      },
      "outputs": [],
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=4):\n",
        "            prompt = gr.Textbox(label=\"Your prompt\") #Give prompt some real estate\n",
        "        with gr.Column(scale=1, min_width=50):\n",
        "            btn = gr.Button(\"Submit\") #Submit button side by side!\n",
        "    with gr.Accordion(\"Advanced options\", open=False): #Let's hide the advanced options!\n",
        "            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
        "                      info=\"In many steps will the denoiser denoise the image?\")\n",
        "                    guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
        "                      info=\"Controls how much the text prompt influences the result\")\n",
        "                with gr.Column():\n",
        "                    width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n",
        "                    height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n",
        "    output = gr.Image(label=\"Result\") #Move the output up too\n",
        "\n",
        "    btn.click(fn=generate, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\n",
        "\n",
        "gr.close_all()\n",
        "demo.launch(share=True, server_port=int(os.environ['PORT4']))\n",
        "gr.close_all()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWC7gHLgduCv"
      },
      "source": [
        "> ## Describe-and-Generate game"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ffl8n_oOdxys"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8O-Dzzhad2rA"
      },
      "outputs": [],
      "source": [
        "# Helper function\n",
        "import requests, json\n",
        "\n",
        "#Here we are going to call multiple endpoints!\n",
        "def get_completion(inputs, parameters=None, ENDPOINT_URL=\"\"):\n",
        "    headers = {\n",
        "      \"Authorization\": f\"Bearer {hf_api_key}\",\n",
        "      \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    data = { \"inputs\": inputs }\n",
        "    if parameters is not None:\n",
        "        data.update({\"parameters\": parameters})\n",
        "    response = requests.request(\"POST\",\n",
        "                                ENDPOINT_URL,\n",
        "                                headers=headers,\n",
        "                                data=json.dumps(data))\n",
        "    return json.loads(response.content.decode(\"utf-8\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "iHIFskf-d5z9"
      },
      "outputs": [],
      "source": [
        "#text-to-image\n",
        "TTI_ENDPOINT = os.environ['HF_API_TTI_BASE']\n",
        "#image-to-text\n",
        "ITT_ENDPOINT = os.environ['HF_API_ITT_BASE']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "o_b6lky6d-S1"
      },
      "outputs": [],
      "source": [
        "#Bringing the functions from lessons 3 and 4!\n",
        "def image_to_base64_str(pil_image):\n",
        "    byte_arr = io.BytesIO()\n",
        "    pil_image.save(byte_arr, format='PNG')\n",
        "    byte_arr = byte_arr.getvalue()\n",
        "    return str(base64.b64encode(byte_arr).decode('utf-8'))\n",
        "\n",
        "def base64_to_pil(img_base64):\n",
        "    base64_decoded = base64.b64decode(img_base64)\n",
        "    byte_stream = io.BytesIO(base64_decoded)\n",
        "    pil_image = Image.open(byte_stream)\n",
        "    return pil_image\n",
        "\n",
        "def captioner(image):\n",
        "    base64_image = image_to_base64_str(image)\n",
        "    result = get_completion(base64_image, None, ITT_ENDPOINT)\n",
        "    return result[0]['generated_text']\n",
        "\n",
        "def generate(prompt):\n",
        "    output = get_completion(prompt, None, TTI_ENDPOINT)\n",
        "    result_image = base64_to_pil(output)\n",
        "    return result_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tzWF4wGgeCIg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "e2d3e685-b566-4281-9ce5-cdfa634eff80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7861\n",
            "Closing server running on port: 7860\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://8d550b3c448d1dcf42.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8d550b3c448d1dcf42.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import gradio as gr\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Describe-and-Generate game 🖍️\")\n",
        "    image_upload = gr.Image(label=\"Your first image\",type=\"pil\")\n",
        "    btn_caption = gr.Button(\"Generate caption\")\n",
        "    caption = gr.Textbox(label=\"Generated caption\")\n",
        "\n",
        "    btn_caption.click(fn=captioner, inputs=[image_upload], outputs=[caption])\n",
        "\n",
        "gr.close_all()\n",
        "demo.launch(share=True)#, server_port=int(os.environ['PORT1']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4CgUm_neFER"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doKK1fIpeFKw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XrRb3y7eFtC"
      },
      "outputs": [],
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Describe-and-Generate game 🖍️\")\n",
        "    image_upload = gr.Image(label=\"Your first image\",type=\"pil\")\n",
        "    btn_caption = gr.Button(\"Generate caption\")\n",
        "    caption = gr.Textbox(label=\"Generated caption\")\n",
        "    btn_image = gr.Button(\"Generate image\")\n",
        "    image_output = gr.Image(label=\"Generated Image\")\n",
        "    btn_caption.click(fn=captioner, inputs=[image_upload], outputs=[caption])\n",
        "    btn_image.click(fn=generate, inputs=[caption], outputs=[image_output])\n",
        "\n",
        "gr.close_all()\n",
        "demo.launch(share=True, server_port=int(os.environ['PORT2']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vexgwu80eP_s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "697dc1fc-695b-40be-fda9-11ac4db6f358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7861\n",
            "Closing server running on port: 7860\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://bc90d09a9ef6b3cfbe.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://bc90d09a9ef6b3cfbe.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "def caption_and_generate(image):\n",
        "    caption = captioner(image)\n",
        "    image = generate(caption)\n",
        "    return [caption, image]\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Describe-and-Generate game 🖍️\")\n",
        "    image_upload = gr.Image(label=\"Your first image\",type=\"pil\")\n",
        "    btn_all = gr.Button(\"Caption and generate\")\n",
        "    caption = gr.Textbox(label=\"Generated caption\")\n",
        "    image_output = gr.Image(label=\"Generated Image\")\n",
        "\n",
        "    btn_all.click(fn=caption_and_generate, inputs=[image_upload], outputs=[caption, image_output])\n",
        "\n",
        "gr.close_all()\n",
        "demo.launch(share=True) #, server_port=int(os.environ['PORT3']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kzJnbpAs4KU"
      },
      "source": [
        "> # Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "9wK6LI6xL_1N",
        "outputId": "20c3fbfc-299f-4501-db03-dd5a460b3a98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7861\n",
            "Closing server running on port: 7863\n",
            "Closing server running on port: 7860\n",
            "Closing server running on port: 7864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/blocks.py:528: UserWarning: Cannot load peach. Caught Exception: The space peach does not exist\n",
            "  warnings.warn(f\"Cannot load {theme}. Caught Exception: {str(e)}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://02581504ae8d14ed53.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://02581504ae8d14ed53.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "gr.close_all()\n",
        "\n",
        "\n",
        "with gr.Blocks() as interface:\n",
        "    gr.Markdown(\"# Building Generative AI Applications with Gradio\")\n",
        "    with gr.Tab(\"NLP tasks with a simple interface\"):\n",
        "        with gr.Tab(\"Text Summarization\"):\n",
        "          gr.Interface(fn=summarize, inputs=\"text\", outputs=\"text\",\n",
        "                       title=\"Building a text summarization app with shleifer/distilbart-cnn-12-6\",\n",
        "                       description=\"Text summarization using the `shleifer/distilbart-cnn-12-6` model under the hood!\",\n",
        "                       allow_flagging=\"never\",\n",
        "                       #Here we introduce a new tag, examples, easy to use examples for your application\n",
        "                       examples=['''The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side.  During its construction, the Eiffel Tower surpassed the Washington  Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure  to reach a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the  Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.'''])\n",
        "        with gr.Tab(\"Named Entity Recognition\"):\n",
        "          gr.Interface(fn=ner3,\n",
        "                    inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)],\n",
        "                    outputs=[gr.HighlightedText(label=\"Text with entities\")],\n",
        "                    title=\"NER with dslim/bert-base-NER\",\n",
        "                    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n",
        "                    allow_flagging=\"never\",\n",
        "                    #Here we introduce a new tag, examples, easy to use examples for your application\n",
        "                    examples=[\"My name is Andrew and I live in California\", \"My name is Poli and work at HuggingFace\"])\n",
        "        with gr.Tab(\"Question Answering Machine\"):\n",
        "          gr.Interface.from_pipeline(question_answerer,\n",
        "                    title = title,\n",
        "                    theme = \"peach\",\n",
        "                    allow_flagging=\"never\",\n",
        "                    examples = [[context, question]],\n",
        "                    description = 'Input context and question, then get answers!'\n",
        "                                     )\n",
        "    with gr.Tab(\"CVs tasks with a simple interface\"):\n",
        "        #gr.Image(\"/content/387550498_602696475220595_8520824588698160254_n.jpg\")\n",
        "        #gr.Button(\"New Tiger\")\n",
        "        with gr.Tab(\"Image captioning\"):\n",
        "          gr.Interface(fn=captioner,\n",
        "                    inputs=[gr.Image(label=\"Upload image\", type=\"pil\")],\n",
        "                    outputs=[gr.Textbox(label=\"Caption\")],\n",
        "                    title=\"Image Captioning with BLIP\",\n",
        "                    description=\"Caption any image using the BLIP model\",\n",
        "                    allow_flagging=\"never\",\n",
        "                    examples=[\"christmas_dog.jpeg\", \"bird_flight.jpeg\", \"cow.jpeg\"])\n",
        "        with gr.Tab(\"Image generation\"):\n",
        "          gr.Interface(fn=generate1,\n",
        "                    inputs=[gr.Textbox(label=\"Your prompt\")],\n",
        "                    outputs=[gr.Image(label=\"Result\")],\n",
        "                    title=\"Image Generation with Stable Diffusion\",\n",
        "                    description=\"Generate any image with Stable Diffusion\",\n",
        "                    allow_flagging=\"never\",\n",
        "                    examples=[\"the spirit of a tamagotchi wandering in the city of Vienna\",\"a mecha robot in a favela\",\"papercut, a cute fox\",\"Self-portrait oil painting, a beautiful cyborg with golden hair, 8k\"])\n",
        "        with gr.Tab(\"Describe-and-Generate game\"):\n",
        "          gr.Markdown(\"# Describe-and-Generate game 🖍️\")\n",
        "          image_upload = gr.Image(label=\"Your first image\",type=\"pil\")\n",
        "          btn_all = gr.Button(\"Caption and generate\")\n",
        "          caption = gr.Textbox(label=\"Generated caption\")\n",
        "          image_output = gr.Image(label=\"Generated Image\")\n",
        "          btn_all.click(fn=caption_and_generate, inputs=[image_upload], outputs=[caption, image_output])\n",
        "\n",
        "\n",
        "interface.launch()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7zHjjYEFAOZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> # Additional functions\n",
        "\n",
        "**#** *Ref:* [Link](https://github.com/ArslanKAS/Building-Machine-Learning-Demos-with-Gradio/blob/main/07_UI.ipynb)"
      ],
      "metadata": {
        "id": "OtOjN_EAAOrV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## Show Gradio BarGraph"
      ],
      "metadata": {
        "id": "qZyCILbWAcFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "\n",
        "def agent_function(agent):\n",
        "    agent_data = BSA_results[BSA_results[\"Agent Name\"]==agent]\n",
        "    report = agent_data[\"Agent Report\"].values[0]\n",
        "    guidelines = agent_data[\"Guideline/Tips\"].values[0]\n",
        "    calls = agent_data[\"Total Calls\"].values[0]\n",
        "    sales = agent_data[\"Total Sales\"].values[0]\n",
        "    state = agent_data[\"Agent State\"].values[0]\n",
        "    agent_features = eval(agent_data['Agent (Average) LIME Features'].reset_index(drop=True)[0])\n",
        "    top_agent_features = eval(agent_data['Top Agents (Average) LIME Features'].reset_index(drop=True)[0])\n",
        "    simple = pd.DataFrame(\n",
        "    {\n",
        "        \"Features\": agent_features.keys(),\n",
        "        \"Agent\": agent_features.values(),\n",
        "        \"Top_Agents\": top_agent_features.values(),\n",
        "    })\n",
        "\n",
        "\n",
        "    return calls, sales, state, report, guidelines, simple\n",
        "\n",
        "simple = pd.DataFrame(\n",
        "{\n",
        "    \"Features\": agent_features.keys(),\n",
        "    \"Agent\": agent_features.values(),\n",
        "    \"Top_Agents\": top_agent_features.values(),\n",
        "})\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Agent Reporting Dashboard\")\n",
        "    with gr.Row():\n",
        "        inp = [gr.Dropdown(BSA_results[\"Agent Name\"].values.tolist(), label=\"Select Agent\")]\n",
        "        out1 = [gr.Text(label=\"Total Calls\"),\n",
        "              gr.Text(label=\"Total Sales\"),\n",
        "              gr.Text(label=\"Agent State\")]\n",
        "    with gr.Row():\n",
        "        out2 = [gr.Text(label=\"Agent Performance Report\"),\n",
        "              gr.Text(label=\"Training Guidelines/Tips\")]\n",
        "    with gr.Row():\n",
        "        out3 = [gr.BarPlot(\n",
        "                        simple,\n",
        "                        x=\"Features\",\n",
        "                        y=\"Agent\",\n",
        "                        title=\"Agent Vs Top Agents (Average)\",\n",
        "                        tooltip=[\"Features\", \"Agent\"],\n",
        "                        y_lim=[0, 100],\n",
        "                        )]\n",
        "\n",
        "    btn = gr.Button(\"Run\")\n",
        "    btn.click(fn=agent_function, inputs=inp, outputs=(out1+out2+out3))\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "SSvWQXAKAZIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## Show MatplotLib Graph on Gradio"
      ],
      "metadata": {
        "id": "RKxr5mdAAkjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def agent_comparison_chart(agent_name, data):\n",
        "    # Find the row index where 'Agent Name' matches the provided agent_name\n",
        "    index = data['Agent Name'].index[data['Agent Name'] == agent_name].tolist()\n",
        "    if not index:\n",
        "        print(f\"Agent {agent_name} not found in the dataset.\")\n",
        "        return\n",
        "\n",
        "    # Extract emotions and values for the specified agent and top agents\n",
        "    agent_features = eval(data['Agent (Average) LIME Features'][index[0]])\n",
        "    top_agent_features = eval(data['Top Agents (Average) LIME Features'][index[0]])\n",
        "\n",
        "    emotions = list(agent_features.keys())\n",
        "    agent_values = list(agent_features.values())\n",
        "    top_agent_values = list(top_agent_features.values())\n",
        "\n",
        "    bar_width = 0.4\n",
        "    positions = range(len(emotions))\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    agent_bars = plt.bar(positions, agent_values, bar_width, label=f'Agent {agent_name} (Average) LIME Features')\n",
        "    top_agent_bars = plt.bar([pos + bar_width for pos in positions], top_agent_values, bar_width, label='Top Agents (Average) LIME Features')\n",
        "    plt.xlabel('Emotions')\n",
        "    plt.ylabel('Values')\n",
        "    plt.title(f'Comparison of Emotion Values between Agent {agent_name} and Top Agents')\n",
        "    plt.xticks([pos + bar_width / 2 for pos in positions], emotions, rotation=90)\n",
        "    plt.legend()\n",
        "\n",
        "    # Display values on top of the bars\n",
        "    for bar, value in zip(agent_bars, agent_values):\n",
        "        plt.text(bar.get_x() + bar.get_width() / 2, value, str(int(value)), ha='center', va='bottom')\n",
        "    for bar, value in zip(top_agent_bars, top_agent_values):\n",
        "        plt.text(bar.get_x() + bar.get_width() / 2, value, str(int(value)), ha='center', va='bottom')\n",
        "\n",
        "    return plt\n",
        "\n",
        "\n",
        "def agent_function(agent):\n",
        "    agent_data = BSA_results[BSA_results[\"Agent Name\"]==agent]\n",
        "    report = agent_data[\"Agent Report\"].values[0]\n",
        "    guidelines = agent_data[\"Guideline/Tips\"].values[0]\n",
        "    calls = agent_data[\"Total Calls\"].values[0]\n",
        "    sales = agent_data[\"Total Sales\"].values[0]\n",
        "    state = agent_data[\"Agent State\"].values[0]\n",
        "    return calls, sales, state, report, guidelines, agent_comparison_chart(agent, BSA_results)\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Agent Reporting Dashboard\")\n",
        "    with gr.Row():\n",
        "        inp = [gr.Dropdown(BSA_results[\"Agent Name\"].values.tolist(), label=\"Select Agent\")]\n",
        "        out1 = [gr.Text(label=\"Total Calls\"),\n",
        "              gr.Text(label=\"Total Sales\"),\n",
        "              gr.Text(label=\"Agent State\")]\n",
        "    with gr.Row():\n",
        "        out2 = [gr.Text(label=\"Agent Performance Report\"),\n",
        "              gr.Text(label=\"Training Guidelines/Tips\")]\n",
        "    with gr.Row():\n",
        "        out3 = [gr.Plot(scale=2)]\n",
        "\n",
        "    btn = gr.Button(\"Run\")\n",
        "    btn.click(fn=agent_function, inputs=inp, outputs=(out1+out2+out3))\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "hA0S8etFAnz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## Advanced UI"
      ],
      "metadata": {
        "id": "eZKFV5gsAzdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import calendar\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def agent_feature_calls(month, agent, projectid, features):\n",
        "    start_time, end_time = get_month_dates(month)\n",
        "    return agent_lowest_calls(agent, start_time, end_time, projectid, features)\n",
        "\n",
        "def top_agent_feature_calls(month, agent, projectid, features):\n",
        "    start_time, end_time = get_month_dates(month)\n",
        "    return agent_top_calls(agent, start_time, end_time, projectid, features)\n",
        "\n",
        "def top_diff_features(data):\n",
        "    data = data.reset_index(drop=True)\n",
        "    agent_f = eval(data['Agent (Average) Features'][0])\n",
        "    top_agent_f = eval(data['Top Agents (Average) Features'][0])\n",
        "    percentage_differences = {key: (abs(top_agent_f.get(key, 0) - agent_f.get(key, 0))/ ((top_agent_f.get(key, 0) + agent_f.get(key, 0))/2))*100  for key in set(top_agent_f)}\n",
        "    percentage_differences = dict(sorted(percentage_differences.items(), key=lambda x:x[1], reverse=True))\n",
        "    top_3_features_with_max_difference = list(percentage_differences.keys())[:3]\n",
        "    return top_3_features_with_max_difference\n",
        "\n",
        "def get_month_dates(month):\n",
        "    # Get the current year\n",
        "    current_year = datetime.now().year\n",
        "    # Get the first day of the month\n",
        "    start_date = datetime(current_year, int(month), 1)\n",
        "    # Get the last day of the month\n",
        "    _, last_day = calendar.monthrange(current_year, month)\n",
        "    end_date = datetime(current_year, month, last_day)\n",
        "    return start_date.strftime(\"%Y-%m-%d\"), end_date.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "def agent_function(month, agent, projectid):\n",
        "    start_time, end_time = get_month_dates(month)\n",
        "    agent_data = user_inputs(start_time, end_time, projectid, agent, con)\n",
        "    report = agent_data[\"Agent Report\"].values[0]\n",
        "    guidelines = agent_data[\"Guideline/Tips\"].values[0]\n",
        "    calls = agent_data[\"Total Calls\"].values[0]\n",
        "    sales = agent_data[\"Total Sales\"].values[0]\n",
        "    score = agent_data[\"Score\"].values[0]\n",
        "    state = agent_data[\"Agent State\"].values[0]\n",
        "    projectId = agent_data[\"ProjectID\"].values[0]\n",
        "    features = top_diff_features(agent_data)\n",
        "    top_agents = eval(agent_data[\"Top Agent Names\"].values[0])\n",
        "    return (\n",
        "        calls,\n",
        "        sales,\n",
        "        score,\n",
        "        state,\n",
        "        report,\n",
        "        guidelines,\n",
        "        agent_comparison_chart(agent, agent_data),\n",
        "        agent_talk_chart(agent, agent_data),\n",
        "        agent_difference_percentages(agent, agent_data),\n",
        "        sentiment_diff(agent, agent_data),\n",
        "        top_agents,\n",
        "        features\n",
        "    )\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Agent Reporting Dashboard\")\n",
        "    # INPUTS\n",
        "    with gr.Row():\n",
        "        month_sel = [gr.Dropdown([1,2,3,4,5], label=\"Select Month\")]\n",
        "        agent_sel = [gr.Dropdown(['Abdul Ali', 'Yono Noyman', 'Aditya Chawla'], label=\"Select Agent\")]\n",
        "        project_sel = [gr.Text(label=\"ProjectID\", value=168)]\n",
        "        run_button = gr.Button(\"Run\")\n",
        "\n",
        "    # OUTPUTS\n",
        "    with gr.Row():\n",
        "        calls_output = [gr.Text(label=\"Total Calls\"),\n",
        "                          gr.Text(label=\"Total Sales\"),\n",
        "                          gr.Text(label=\"Score\"),\n",
        "                          gr.Text(label=\"Agent State\")]\n",
        "    with gr.Row():\n",
        "        report_output = [gr.Text(label=\"Agent Performance Report\"),\n",
        "                          gr.Text(label=\"Training Guidelines/Tips\")]\n",
        "    with gr.Row():\n",
        "        emotion_graph = [gr.Plot(label=\"Emotions Graph\")]\n",
        "    with gr.Row():\n",
        "        talk_graph = [gr.Plot(label=\"Talk Metrics Graph\")]\n",
        "    with gr.Row():\n",
        "        differences_graph = [gr.Plot(label=\"Percentange Differences Graph\")]\n",
        "    with gr.Row():\n",
        "        sentiment_graph = [gr.Plot(label=\"Sentiment Differences Graph\")]\n",
        "    with gr.Row():\n",
        "        top_agents_names = [gr.Text(label=\"Top 5 Agents\")]\n",
        "        top_feature_diff = [gr.Text(label=\"Top % Difference Features\")]\n",
        "        top_feature_drop = [gr.Dropdown(top_feature_diff[0].value, label=\"Select Feature\")]\n",
        "    with gr.Row():\n",
        "        agent_calls_button = gr.Button(\"Agent Calls\")\n",
        "        agents_calls = gr.Dataframe(label=\"Agent's Lowest Calls\")\n",
        "    with gr.Row():\n",
        "        top_agent_calls_button = gr.Button(\"Top Agent Calls\")\n",
        "        top_agents_calls = gr.Dataframe(label=\"Top Agent's Highest Calls\")\n",
        "\n",
        "    # BUTTONS\n",
        "    inputs = month_sel + agent_sel + project_sel\n",
        "    outputs = calls_output + report_output + emotion_graph + talk_graph + differences_graph + sentiment_graph + top_agents_names + top_feature_diff\n",
        "    run_button.click(agent_function, inputs=inputs, outputs=outputs)\n",
        "\n",
        "    agent_calls_inputs = inputs + top_feature_diff\n",
        "    agent_calls_button.click(agent_feature_calls, inputs=agent_calls_inputs, outputs=agents_calls)\n",
        "\n",
        "    top_agents_inputs = month_sel + top_agents_names + project_sel + top_feature_diff\n",
        "    top_agent_calls_button.click(top_agent_feature_calls, inputs=top_agents_inputs, outputs=top_agents_calls)\n",
        "\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "YCowPiwFA1XC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}