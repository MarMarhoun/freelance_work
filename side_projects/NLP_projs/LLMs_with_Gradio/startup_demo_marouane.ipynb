{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP7AowyELmSLHeDlF2XuWZ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarMarhoun/freelance_work/blob/main/side_projects/NLP_projs/LLMs_with_Gradio/startup_demo_marouane.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web App for Text Similarity Using Gradio and Hugging Face's Language Models - Demo\n",
        "\n",
        "This web app leverages Gradio and Hugging Face's language models (LLMs) to analyze text similarity based on user prompts. This app is designed to work with video subtitles or transcriptions, allowing users to extract meaningful insights from video content. You can either provide a link to a video (such as from YouTube) or upload a transcription file locally.\n",
        "\n",
        "This web app is designed to enhance your understanding of video content by providing a robust analysis of text similarity, ensuring that you capture all essential information effectively.\n",
        "\n",
        "## Key Features of the Web App:\n",
        "\n",
        "\n",
        "1.   **Text Similarity Analysis:** The app will analyze the extracted text from the video and compare it to the user-provided prompt. It will calculate a similarity score that indicates how closely the prompt aligns with the content of the video.\n",
        "2.   **Similarity Scoring:** The application will provide a score or probability indicating whether the prompt text falls within the scope of the extracted text. This score will help users understand the relevance of their prompt in relation to the video content.\n",
        "3. **Gap Identification:** The app will highlight and mention any significant gaps or major points that are missing from the prompt compared to the extracted text. This feature ensures that users are aware of critical information that may not have been included in their prompt.\n",
        "\n",
        "### Output:\n",
        "\n",
        "+ Similarity Score: A numerical value representing the degree of similarity between the prompt and the extracted text.\n",
        "+ Gap Analysis: A detailed report highlighting key points or concepts that are present in the extracted text but absent from the prompt, providing users with a comprehensive understanding of the content.\n",
        "\n",
        "### Test Video:\n",
        "To demonstrate the functionality of this web app, please provide a test video link or upload a transcription file.\n",
        "\n",
        "> Test video: https://www.youtube.com/watch?v=8kK2zwjRV0M\n",
        "\n",
        "```\n",
        "For any inquiries or support, feel free to reach out to Marouane MARHOUN @t marmarhoun@gmail.com\n",
        "\n",
        "Github profile: https://github.com/MarMarhoun/\n",
        "LinkedIn profile: https://www.linkedin.com/in/marmarhoun/\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "aVdLalfExOGR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqt50107tq68"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   Extract subtitles from a YouTube video: We can use the youtube-transcript-api library to fetch subtitles.\n",
        "2.   Use a pre-trained language model: We will utilize a model from Hugging Face to compute text similarity.\n",
        "3. Build the Gradio interface: This will allow users to upload a video or provide a YouTube link, input a prompt, and see the result\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v6_f9L-i9Zb-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install the librarires"
      ],
      "metadata": {
        "id": "pgXthVzN9VWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio youtube-transcript-api transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-7s0-U-xQrr",
        "outputId": "7cf14b8c-be86-4ab8-fa3c-5b3e93a562e4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.23.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-1.0.3-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.29.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.23.1-py3-none-any.whl (51.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading youtube_transcript_api-1.0.3-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, groovy, ffmpy, aiofiles, youtube-transcript-api, starlette, nvidia-cusparse-cu12, nvidia-cudnn-cu12, safehttpx, nvidia-cusolver-cu12, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.23.1 gradio-client-1.8.0 groovy-0.1.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.2 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0 youtube-transcript-api-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers wordcloud matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGJolA2wHwvm",
        "outputId": "618a72dc-cf1f-4f4a-f7a6-2a5da9d4a71e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.11/dist-packages (1.9.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.50.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.29.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from wordcloud) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Before Summarization of the Extracted Text"
      ],
      "metadata": {
        "id": "T17LEr9dK8Xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound, VideoUnavailable\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import re\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "\n",
        "# Load the similarity model once at the start\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Function to extract subtitles from a YouTube video with error handling\n",
        "def extract_subtitles(video_url):\n",
        "    try:\n",
        "        video_id = video_url.split(\"v=\")[-1]\n",
        "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "        # Combine the text from the transcript\n",
        "        full_text = \" \".join([entry['text'] for entry in transcript])\n",
        "        return full_text\n",
        "    except NoTranscriptFound:\n",
        "        return \"Error: No transcript available for this video.\"\n",
        "    except VideoUnavailable:\n",
        "        return \"Error: The video is unavailable or does not have subtitles.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: An unexpected error occurred: {str(e)}\"\n",
        "\n",
        "# Function to save extracted text to a file\n",
        "def save_extracted_text(video_id, text):\n",
        "    with open(f\"{video_id}_transcript.txt\", \"w\") as f:\n",
        "        f.write(text)\n",
        "\n",
        "# Function to create a word cloud image\n",
        "def create_wordcloud(text, filename, title=None):\n",
        "    if not text.strip():  # Check if the text is empty\n",
        "        return None\n",
        "\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='black').generate(text)\n",
        "\n",
        "    plt.figure(figsize=(18, 6))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Add title if provided\n",
        "    if title:\n",
        "        plt.title(title, fontsize=24, color='black')  # Customize title appearance as needed\n",
        "\n",
        "    plt.savefig(filename, format='png')\n",
        "    plt.close()\n",
        "    return filename\n",
        "\n",
        "# Function to compute similarity and gaps\n",
        "def analyze_text(prompt, video_url):\n",
        "    # Extract subtitles\n",
        "    extracted_text = extract_subtitles(video_url)\n",
        "\n",
        "    if \"Error\" in extracted_text:\n",
        "        return extracted_text, []\n",
        "\n",
        "    # Save the extracted text for future use\n",
        "    video_id = video_url.split(\"v=\")[-1]\n",
        "    save_extracted_text(video_id, extracted_text)\n",
        "\n",
        "    # Ensure prompt and extracted_text are not empty\n",
        "    if not prompt or not extracted_text:\n",
        "        return \"Error: Prompt or extracted text is empty.\", []\n",
        "\n",
        "    # Compute similarity score\n",
        "    try:\n",
        "        embeddings1 = model.encode(prompt, convert_to_tensor=True)\n",
        "        embeddings2 = model.encode(extracted_text, convert_to_tensor=True)\n",
        "        similarity_score = util.cos_sim(embeddings1, embeddings2).item()\n",
        "    except Exception as e:\n",
        "        return f\"Error: An issue occurred while computing similarity: {str(e)}\", []\n",
        "\n",
        "    # Create a similarity message\n",
        "    #similarity_message = f\"Similarity Score: {similarity_score:.2f}\"\n",
        "    similarity_message = f\"Similarity Score: {similarity_score * 100:.2f}% (This score indicates how closely the prompt matches the extracted text.)\"\n",
        "\n",
        "    # Find gaps in the prompt\n",
        "    extracted_sentences = re.split(r'(?<=[.!?]) +', extracted_text)\n",
        "    missing_points = [sentence for sentence in extracted_sentences if prompt.lower() not in sentence.lower()]\n",
        "    # Create the word cloud for missing points\n",
        "    missing_wordcloud_path = create_wordcloud(\" \".join(missing_points), 'missing_wordcloud.png', title='Missing Points WordCloud') if missing_points else None\n",
        "\n",
        "\n",
        "    # Format missing points for better presentation\n",
        "    if missing_points:\n",
        "        formatted_missing_points = \"\\n\".join([f\"- {point.strip()}\" for point in missing_points])\n",
        "        missing_points_message = f\"Missing Points ({len(missing_points)}):\\n{formatted_missing_points}\"\n",
        "    else:\n",
        "        missing_points_message = \"No missing points found.\"\n",
        "\n",
        "    return similarity_message, missing_points_message, missing_wordcloud_path\n",
        "\n",
        "# Function to handle text extraction and update the output\n",
        "def extract_and_display_text(video_url):\n",
        "    extracted_text = extract_subtitles(video_url)\n",
        "    # Create the word cloud for the extracted text with a title\n",
        "    extracted_wordcloud_path = create_wordcloud(extracted_text, 'extracted_wordcloud.png', title='Extracted Text WordCloud')\n",
        "\n",
        "    return extracted_text, extracted_wordcloud_path\n",
        "\n",
        "# Gradio interface\n",
        "def gradio_interface(prompt, video_url):\n",
        "    score, gaps, missing_wordcloud_path= analyze_text(prompt, video_url)\n",
        "    return score, gaps, missing_wordcloud_path\n",
        "\n",
        "# Create Gradio app\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"<h2 style='text-align: center;'>Text Similarity Analysis from Video</h2>\")\n",
        "\n",
        "    # Example video URLs\n",
        "    gr.Markdown(\"### Example YouTube Video URLs\")\n",
        "    gr.Markdown(\"- [DNA Structure and Replication](https://www.youtube.com/watch?v=8kK2zwjRV0M)\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            video_url = gr.Textbox(label=\"YouTube Video URL\", placeholder=\"Enter the YouTube video URL here...\")\n",
        "            extracted_text_output = gr.Textbox(label=\"Extracted Text\", interactive=False, lines=10)\n",
        "            extracted_wordcloud = gr.Image(label=\"Extracted Text Word Cloud\", interactive=False)\n",
        "            extract_btn = gr.Button(\"Extract Text\")\n",
        "\n",
        "        with gr.Column():\n",
        "            prompt = gr.Textbox(label=\"Prompt Text\", placeholder=\"Enter your prompt text here...\")\n",
        "\n",
        "            similarity_output = gr.Textbox(label=\"Similarity Score\", interactive=False)\n",
        "            gaps_output = gr.Textbox(label=\"Missing Points\", interactive=False)\n",
        "\n",
        "            missing_wordcloud = gr.Image(label=\"Missing Points Word Cloud\", interactive=False)\n",
        "            submit_btn = gr.Button(\"Analyze\")\n",
        "\n",
        "    # Button click events\n",
        "    extract_btn.click(extract_and_display_text, inputs=video_url, outputs=[extracted_text_output, extracted_wordcloud])\n",
        "    submit_btn.click(gradio_interface, inputs=[prompt, video_url], outputs=[similarity_output, gaps_output, missing_wordcloud])\n",
        "\n",
        "     gr.Markdown(\"### Example Prompts\")\n",
        "    gr.Markdown(\"- Explain the structure of DNA and its significance in genetics.\")\n",
        "    gr.Markdown(\"- DNA sequencing is used in modern medicine\")\n",
        "    gr.Markdown(\"- DNA plays a weak role in the process of protein synthesis.\")\n",
        "    gr.Markdown(\"- DNA sequencing has major implications in modern medicine.\")\n",
        "    gr.Markdown(\"- How does DNA replication occur, and why is it important for cell division?\")\n",
        "    gr.Markdown(\"- What are the ethical considerations surrounding genetic engineering and DNA manipulation?\")\n",
        "\n",
        "# Launch the app\n",
        "app.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "nfM8mr9TiZyC",
        "outputId": "143803cb-2797-4e66-c38a-5a3d86992c01"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://46bf89108ea42410a0.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://46bf89108ea42410a0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# After Summarization of the Extracted Text"
      ],
      "metadata": {
        "id": "DqkJyEvpKy3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound, VideoUnavailable\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import re\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Load the similarity model and summarization model once at the start\n",
        "similarity_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "summarization_model = pipeline(\"summarization\")\n",
        "\n",
        "# Function to extract subtitles from a YouTube video with error handling\n",
        "def extract_subtitles(video_url):\n",
        "    try:\n",
        "        video_id = video_url.split(\"v=\")[-1]\n",
        "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "        # Combine the text from the transcript\n",
        "        full_text = \" \".join([entry['text'] for entry in transcript])\n",
        "        return full_text\n",
        "    except NoTranscriptFound:\n",
        "        return \"Error: No transcript available for this video.\"\n",
        "    except VideoUnavailable:\n",
        "        return \"Error: The video is unavailable or does not have subtitles.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: An unexpected error occurred: {str(e)}\"\n",
        "\n",
        "# Function to save extracted text to a file\n",
        "def save_extracted_text(video_id, text):\n",
        "    with open(f\"{video_id}_transcript.txt\", \"w\") as f:\n",
        "        f.write(text)\n",
        "\n",
        "\n",
        "# Function to create a word cloud image\n",
        "def create_wordcloud(text, filename, title=None):\n",
        "    if not text.strip():  # Check if the text is empty\n",
        "        return None\n",
        "\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "\n",
        "    plt.figure(figsize=(18, 6))\n",
        "    plt.imshow(wordcloud, interpolation='bicubic')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Add title if provided\n",
        "    if title:\n",
        "        plt.title(title, fontsize=24, color='black')  # Customize title appearance as needed\n",
        "\n",
        "    plt.savefig(filename, format='png')\n",
        "    plt.close()\n",
        "    return filename\n",
        "\n",
        "\n",
        "# Function to compute similarity and gaps\n",
        "def analyze_text(prompt, video_url):\n",
        "    # Extract subtitles\n",
        "    extracted_text = extract_subtitles(video_url)\n",
        "\n",
        "    if \"Error\" in extracted_text:\n",
        "        return extracted_text, []\n",
        "\n",
        "    # Save the extracted text for future use\n",
        "    video_id = video_url.split(\"v=\")[-1]\n",
        "    save_extracted_text(video_id, extracted_text)\n",
        "\n",
        "    # Ensure prompt and extracted_text are not empty\n",
        "    if not prompt or not extracted_text:\n",
        "        return \"Error: Prompt or extracted text is empty.\", []\n",
        "\n",
        "    # Compute similarity score\n",
        "    try:\n",
        "        embeddings1 = similarity_model.encode(prompt, convert_to_tensor=True)\n",
        "        embeddings2 = similarity_model.encode(extracted_text, convert_to_tensor=True)\n",
        "        similarity_score = util.cos_sim(embeddings1, embeddings2).item()\n",
        "    except Exception as e:\n",
        "        return f\"Error: An issue occurred while computing similarity: {str(e)}\", []\n",
        "\n",
        "    # Create a similarity message\n",
        "    #similarity_message = f\"Similarity Score: {similarity_score:.2f}\"\n",
        "    similarity_message = f\"Similarity Score: {similarity_score * 100:.2f}% (This score indicates how closely the prompt matches the extracted text.)\"\n",
        "\n",
        "    # Find gaps in the prompt\n",
        "    extracted_sentences = re.split(r'(?<=[.!?]) +', extracted_text)\n",
        "    missing_points = [sentence for sentence in extracted_sentences if prompt.lower() not in sentence.lower()]\n",
        "    # Create the word cloud for missing points\n",
        "    missing_wordcloud_path = create_wordcloud(\" \".join(missing_points), 'missing_wordcloud_sum.png', title='Missing Points WordCloud from Summarized text') if missing_points else None\n",
        "\n",
        "\n",
        "\n",
        "    # Summarize the major missing points using the summarization model\n",
        "    if missing_points:\n",
        "        # Join missing points into a single string for summarization\n",
        "        missing_text = \" \".join(missing_points)\n",
        "\n",
        "        # Ensure the text is not too long for the summarization model\n",
        "        if len(missing_text) > 1024:  # Adjust the length limit as needed\n",
        "            missing_text = missing_text[:1024]  # Truncate to the first 1024 characters\n",
        "\n",
        "        summarized_missing_points = summarization_model(missing_text, max_length=150, min_length=30, do_sample=False)\n",
        "        major_missing_points = summarized_missing_points[0]['summary_text']\n",
        "    else:\n",
        "        major_missing_points = \"No missing points found.\"\n",
        "\n",
        "    return similarity_message, major_missing_points, missing_wordcloud_path\n",
        "\n",
        "# Function to handle text extraction and update the output\n",
        "def extract_and_display_text(video_url):\n",
        "    extracted_text = extract_subtitles(video_url)\n",
        "    # Create the word cloud for the extracted text with a title\n",
        "    extracted_wordcloud_path = create_wordcloud(extracted_text, 'extracted_wordcloud_sum.png', title='Extracted Text WordCloud')\n",
        "\n",
        "    return extracted_text, extracted_wordcloud_path\n",
        "\n",
        "# Gradio interface\n",
        "def gradio_interface(prompt, video_url):\n",
        "    score, gaps, missing_wordcloud_path = analyze_text(prompt, video_url)\n",
        "    return score, gaps, missing_wordcloud_path\n",
        "\n",
        "# Create Gradio app\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"<h2 style='text-align: center;'>Text Similarity Analysis from Video - with Summarization </h2>\")\n",
        "\n",
        "    # Example video URLs\n",
        "    gr.Markdown(\"### Example YouTube Video URLs\")\n",
        "    gr.Markdown(\"- [DNA Structure and Replication](https://www.youtube.com/watch?v=8kK2zwjRV0M)\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            video_url = gr.Textbox(label=\"YouTube Video URL\", placeholder=\"Enter the YouTube video URL here...\")\n",
        "            extracted_text_output = gr.Textbox(label=\"Extracted Text\", interactive=False, lines=10)\n",
        "            extracted_wordcloud = gr.Image(label=\"Extracted Text Word Cloud\", interactive=False)\n",
        "            extract_btn = gr.Button(\"Extract Text\")\n",
        "\n",
        "\n",
        "        with gr.Column():\n",
        "            prompt = gr.Textbox(label=\"Prompt Text\", placeholder=\"Enter your prompt text here...\")\n",
        "\n",
        "            similarity_output = gr.Textbox(label=\"Similarity Score\", interactive=False)\n",
        "            gaps_output = gr.Textbox(label=\"Missing Points\", interactive=False)\n",
        "\n",
        "            missing_wordcloud = gr.Image(label=\"Missing Points Word Cloud\", interactive=False)\n",
        "            submit_btn = gr.Button(\"Analyze\")\n",
        "\n",
        "    # Button click events\n",
        "    extract_btn.click(extract_and_display_text, inputs=video_url, outputs=[extracted_text_output, extracted_wordcloud])\n",
        "    submit_btn.click(gradio_interface, inputs=[prompt, video_url], outputs=[similarity_output, gaps_output, missing_wordcloud])\n",
        "\n",
        "    gr.Markdown(\"### Example Prompts\")\n",
        "    gr.Markdown(\"- Explain the structure of DNA and its significance in genetics.\")\n",
        "    gr.Markdown(\"- DNA sequencing is used in modern medicine\")\n",
        "    gr.Markdown(\"- DNA plays a weak role in the process of protein synthesis.\")\n",
        "    gr.Markdown(\"- DNA sequencing has major implications in modern medicine.\")\n",
        "    gr.Markdown(\"- How does DNA replication occur, and why is it important for cell division?\")\n",
        "    gr.Markdown(\"- What are the ethical considerations surrounding genetic engineering and DNA manipulation?\")\n",
        "\n",
        "# Launch the app\n",
        "app.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "XQbwAMaxmO8g",
        "outputId": "d57e7501-9898-42a0-e8c3-10e97bad362d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9301be49f0a3723127.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9301be49f0a3723127.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7TtR2Zmhn3Sr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}