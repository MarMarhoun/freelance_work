{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObtHdwMiR+ueXeUe0QHsEK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarMarhoun/freelance_work/blob/main/side_projects/NLP_projs/eda_streamlit/book_sum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Book summarization using streamlit and tensorflow\n",
        "\n",
        "A code to summarize a book using Streamlit and TensorFlow, you can create a user-friendly web application that allows users to upload a book, preprocess the text data, and then generate a summary using a trained summarization model. Here's a step-by-step guide on how to create such an application:\n",
        "\n",
        "Install the required libraries:\n",
        "\n",
        "First, make sure you have installed the necessary libraries. You can install them using the following commands:"
      ],
      "metadata": {
        "id": "xKisxCnaH87j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit tensorflow transformers\n"
      ],
      "metadata": {
        "id": "-bbieKo-IK_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a Streamlit application:\n",
        "\n",
        "Create a new Python file (e.g., app.py) and import the required libraries:"
      ],
      "metadata": {
        "id": "P4YWyjiVIYY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import os\n",
        "\n",
        "# Initialize the summarization pipeline\n",
        "summarizer = pipeline(\"summarization\")\n",
        "\n",
        "# Load the pre-trained model and tokenizer for text summarization\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
        "\n",
        "# Define a function for summarizing text\n",
        "def summarize_text(text, max_length=160, min_length=30, num_beams=4, early_stopping=True):\n",
        "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\")\n",
        "    input_ids = inputs[\"input_ids\"].cuda()\n",
        "    model.to(device)\n",
        "\n",
        "    summary_ids = model.generate(\n",
        "        input_ids,\n",
        "        max_length=max_length,\n",
        "        min_length=min_length,\n",
        "        num_beams=num_beams,\n",
        "        early_stopping=early_stopping,\n",
        "    )\n",
        "\n",
        "    summary = tokenizer.decode(summary_ids[0])\n",
        "    return summary\n",
        "\n",
        "# Define a function for loading the book\n",
        "def load_book(file):\n",
        "    with open(file, \"r\") as f:\n",
        "        book = f.read()\n",
        "    return book\n",
        "\n",
        "# Define a function for preprocessing the book text\n",
        "def preprocess_book(book):\n",
        "    # Add your preprocessing steps here\n",
        "    return book\n",
        "\n",
        "# Define a function for generating the summary\n",
        "def generate_summary(book):\n",
        "    summary = summarize_text(book)\n",
        "    return summary\n",
        "\n",
        "# Define the main function\n",
        "def main():\n",
        "    # Set up the Streamlit app\n",
        "    st.set_page_config(page_title=\"Book Summarizer\", page_icon=\":books:\", layout=\"wide\")\n",
        "\n",
        "    st.title(\"Book Summarizer\")\n",
        "    st.subheader(\"Upload a book and get a summary\")\n",
        "\n",
        "    # Add a file uploader\n",
        "    uploaded_file = st.file_uploader(\"Upload a book\", type=\"txt\")\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        # Load the book\n",
        "        book = load_book(uploaded_file)\n",
        "\n",
        "        # Preprocess the book text\n",
        "        preprocessed_book = preprocess_book(book)\n",
        "\n",
        "        # Generate the summary\n",
        "        summary = generate_summary(preprocessed_book)\n",
        "\n",
        "        # Display the summary\n",
        "        st.subheader(\"Summary\")\n",
        "        st.write(summary)\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "SLCMNdGhIa3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run the app, execute the following command:\n",
        "\n"
      ],
      "metadata": {
        "id": "OPx86N-gIrfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "streamlit run app.py"
      ],
      "metadata": {
        "id": "JbYLuPMcIsXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code provides a basic structure for a Streamlit app that allows users to upload a book, preprocess the text data, and generate a summary using a trained summarization model. You can further customize the preprocessing and summarization functions to improve the results.\n",
        "\n"
      ],
      "metadata": {
        "id": "4Bzedr_xIwPi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To enhance and add advanced features to the code for summarizing a book using Streamlit and TensorFlow, you can consider the following improvements:\n",
        "\n",
        "Add user interface elements for customizing the summary, such as adjusting the length or enabling/disabling certain preprocessing steps.\n",
        "\n",
        "Implement multi-document summarization by splitting the book into smaller chunks and summarizing each chunk separately. Then, combine the summaries to create a summary for the entire book.\n",
        "\n",
        "Incorporate a user authentication system to save and load summaries for specific users.\n",
        "\n",
        "Implement a real-time text editor for users to edit the book text before summarizing.\n",
        "\n",
        "Add a progress bar to show the status of the summary generation process.\n",
        "Implement a feedback system to allow users to rate the quality of the summary and provide suggestions for improvement.\n",
        "\n",
        "Use a more advanced summarization model, such as BART or Pegasus, to improve the quality of the summary.\n",
        "Implement a caching system to speed up the summary generation process for large books.\n",
        "\n",
        "Add a search functionality to allow users to search for specific keywords or phrases in the book and summarize the results.\n",
        "\n",
        "Implement a recommendation system to suggest similar books based on the summary.\n",
        "Here's an example of how you can implement some of these features:\n",
        "\n",
        "app.py:"
      ],
      "metadata": {
        "id": "N-vrywCgJ3Q2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize the summarization pipeline\n",
        "summarizer = pipeline(\"summarization\")\n",
        "\n",
        "# Load the pre-trained model and tokenizer for text summarization\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\").cuda()\n",
        "\n",
        "# Define a function for summarizing text\n",
        "def summarize_text(text, max_length=160, min_length=30, num_beams=4, early_stopping=True):\n",
        "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\")\n",
        "    input_ids = inputs[\"input_ids\"].cuda()\n",
        "    model.to(device)\n",
        "\n",
        "    summary_ids = model.generate(\n",
        "        input_ids,\n",
        "        max_length=max_length,\n",
        "        min_length=min_length,\n",
        "        num_beams=num_beams,\n",
        "        early_stopping=early_stopping,\n",
        "    )\n",
        "\n",
        "    summary = tokenizer.decode(summary_ids[0])\n",
        "    return summary\n",
        "\n",
        "# Define a function for loading the book\n",
        "def load_book(file):\n",
        "    with open(file, \"r\") as f:\n",
        "        book = f.read()\n",
        "    return book\n",
        "\n",
        "# Define a function for preprocessing the book text\n",
        "def preprocess_book(book):\n",
        "    # Add your preprocessing steps here\n",
        "    book = re.sub(r'\\[[0-9]*\\]', '', book)\n",
        "    book = re.sub(r'\\s+', ' ', book)\n",
        "    book = book.strip()\n",
        "    return book\n",
        "\n",
        "# Define a function for generating the summary\n",
        "def generate_summary(book):\n",
        "    summary = summarize_text(book)\n",
        "    return summary\n",
        "\n",
        "# Define the main function\n",
        "def main():\n",
        "    # Set up the Streamlit app\n",
        "    st.set_page_config(page_title=\"Book Summarizer\", page_icon=\":books:\", layout=\"wide\")\n",
        "\n",
        "    st.title(\"Book Summarizer\")\n",
        "    st.subheader(\"Upload a book and get a summary\")\n",
        "\n",
        "    # Add a file uploader\n",
        "    uploaded_file = st.file_uploader(\"Upload a book\", type=\"txt\")\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        # Load the book\n",
        "        book = load_book(uploaded_file)\n",
        "\n",
        "        # Preprocess the book text\n",
        "        preprocessed_book = preprocess_book(book)\n",
        "\n",
        "        # Display the preprocessed book text\n",
        "        st.subheader(\"Preprocessed Book Text\")\n",
        "        st.write(preprocessed_book)\n",
        "\n",
        "        # Generate the summary\n",
        "        summary = generate_summary(preprocessed_book)\n",
        "\n",
        "        # Display the summary\n",
        "        st.subheader(\"Summary\")\n",
        "        st.write(summary)\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "8FB4IXqIKEpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code provides a basic structure for a Streamlit app that allows users to upload a book, preprocess the text data, and generate a summary using a trained summarization model. You can further customize the preprocessing and summarization functions\n",
        "\n"
      ],
      "metadata": {
        "id": "WT12Hw4sKQXM"
      }
    }
  ]
}