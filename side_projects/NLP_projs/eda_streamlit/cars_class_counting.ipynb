{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMj7/fjnz6ZqU0cOn16wMA+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarMarhoun/freelance_work/blob/main/side_projects/NLP_projs/eda_streamlit/cars_class_counting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code for cars classification and counting using online dataset, streamlit and tensorflow\n",
        "\n",
        "The code for cars classification and counting using an online dataset, Streamlit, and TensorFlow, I will provide an example of how to build a simple web app that allows users to upload a dataset, train a model for cars classification, and display the trained model's accuracy and confusion matrix using Streamlit and TensorFlow.\n",
        "\n",
        "First, let's start with the required packages and setup:"
      ],
      "metadata": {
        "id": "D1uOh8wvulkJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGCdgvugub-I"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define functions for model training and evaluation\n",
        "def train_model(x_train, y_train):\n",
        "    # Create a basic model architecture\n",
        "    model = Sequential([\n",
        "        Flatten(input_shape=(x_train.shape[1], x_train.shape[2])),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(),\n",
        "                  loss=SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=[SparseCategoricalAccuracy()])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(x_train, y_train, epochs=10)\n",
        "\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, x_test, y_test):\n",
        "    # Evaluate the model and display the accuracy\n",
        "    _, accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
        "    st.write(f'Accuracy: {round(accuracy * 100, 2)}%')\n",
        "\n",
        "    # Generate predictions\n",
        "    y_pred = tf.argmax(model.predict(x_test), axis=1)\n",
        "\n",
        "    # Display confusion matrix\n",
        "    cm = tf.math.confusion_matrix(y_test, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.ylabel('True label')\n",
        "    st.pyplot()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll create the Streamlit app:\n",
        "\n"
      ],
      "metadata": {
        "id": "WA0wuZLNu0Sg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Title and Intro\n",
        "    st.title('Car Classification and Counting')\n",
        "    st.write('Upload a dataset with images of cars and non-cars, and let the model classify and count them.')\n",
        "\n",
        "    # Upload dataset\n",
        "    dataset = st.file_uploader(\"Choose a dataset\", type=\"zip\")\n",
        "\n",
        "    if dataset:\n",
        "        # Load data\n",
        "        data = pd.read_csv(dataset.name.replace('.zip', '_manifest.csv'))\n",
        "        images = [plt.imread(dataset.name.replace('.zip', '/') + '/' + x) for x in data['image_name']]\n",
        "\n",
        "        # Prepare data\n",
        "        x = np.array(images)\n",
        "        y = data['label'].values\n",
        "\n",
        "        # Split data\n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Train the model\n",
        "        st.subheader('Training the model...')\n",
        "        model = train_model(x_train, y_train)\n",
        "\n",
        "        # Evaluate the model\n",
        "        st.subheader('Evaluating the model...')\n",
        "        evaluate_model(model, x_test, y_test)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "Pxf6LpnpupqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Streamlit app allows users to upload a dataset, trains a simple model for cars classification, and displays the trained model's accuracy and confusion matrix. Note that this is a basic example and can be further enhanced by adding more functionalities, such as data preprocessing, hyperparameter tuning, and better model architecture.\n",
        "\n"
      ],
      "metadata": {
        "id": "visXOmKlu5ZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define functions for model training and evaluation\n",
        "def train_model(x_train, y_train):\n",
        "    # Create a more advanced model architecture\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(x_train.shape[1], x_train.shape[2], 3)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(),\n",
        "                  loss=SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=[SparseCategoricalAccuracy()])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(x_train, y_train, epochs=10)\n",
        "\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, x_test, y_test):\n",
        "    # Evaluate the model and display the accuracy\n",
        "    _, accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
        "    st.write(f'Accuracy: {round(accuracy * 100, 2)}%')\n",
        "\n",
        "    # Generate predictions\n",
        "    y_pred = tf.argmax(model.predict(x_test), axis=1)\n",
        "\n",
        "    # Display confusion matrix\n",
        "    cm = tf.math.confusion_matrix(y_test, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.ylabel('True label')\n",
        "    st.pyplot()\n",
        "\n",
        "# Define a function to load and preprocess the data\n",
        "def load_and_preprocess_data(dataset):\n",
        "    # Load data\n",
        "    data = pd.read_csv(dataset.name.replace('.zip', '_manifest.csv'))\n",
        "    images = [plt.imread(dataset.name.replace('.zip', '/') + '/' + x) for x in data['image_name']]\n",
        "\n",
        "    # Prepare data\n",
        "    x = np.array(images)\n",
        "    y = data['label'].values\n",
        "\n",
        "    # Split data\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    return x_train, x_test, y_train, y_test\n",
        "\n",
        "# Define a function to display the images\n",
        "def display_images(images, labels):\n",
        "    fig, axes = plt.subplots(1, len(images), figsize=(15, 15))\n",
        "    for i, (image, label) in enumerate(zip(images, labels)):\n",
        "        axes[i].imshow(image)\n",
        "        axes[i].set_title(f'Label: {label}')\n",
        "    st.pyplot(plt)\n",
        "\n",
        "# Title and Intro\n",
        "st.title('Car Classification and Counting')\n",
        "st.write('Upload a dataset with images of cars and non-cars, and let the model classify and count them.')\n",
        "\n",
        "# Upload dataset\n",
        "dataset = st.file_uploader(\"Choose a dataset\", type=\"zip\")\n",
        "\n",
        "if dataset:\n",
        "    # Load and preprocess data\n",
        "    x_train, x_test, y_train, y_test = load_and_preprocess_data(dataset)\n",
        "\n",
        "    # Display some images\n",
        "    st.subheader('Sample Images')\n",
        "    display_images(x_train[:5], y_train[:5])\n",
        "\n",
        "    # Train the model\n",
        "    st.subheader('Train the Model')\n",
        "    model = create_model()\n",
        "    history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "    # Display evaluation results\n",
        "    st.subheader('Evaluation Results')\n",
        "    loss, accuracy = model.evaluate(x_test, y_test)\n",
        "    st.write(f'Test Loss: {loss}')\n",
        "    st.write(f'Test Accuracy: {accuracy}')\n",
        "\n",
        "    # Count cars\n",
        "    st.subheader('Cars Counting')\n",
        "    cars_count = count_cars(model, x_test, y_test)\n",
        "    st.write(f'Estimated Number of Cars: {cars_count}')"
      ],
      "metadata": {
        "id": "ED2bvaFvu6E9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I apologize for the confusion, but it seems there is no provided code in the search results for cars classification and counting using Streamlit, TensorFlow, and an online dataset. I will provide a solution that integrates these tools for a simple cars classification task.\n",
        "\n",
        "First, let's start by installing the necessary libraries:"
      ],
      "metadata": {
        "id": "x5U2lEzywbt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit tensorflow pillow matplotlib pandas"
      ],
      "metadata": {
        "id": "pIZUFsIWwcVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, create a Python script named app.py and add the following code:\n",
        "\n"
      ],
      "metadata": {
        "id": "CgaYJ0J4wgmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the data\n",
        "def load_data(data_path):\n",
        "    df = pd.read_csv(data_path)\n",
        "    train_data = df[\"id\"].apply(lambda x: Image.open(f\"images/{x}.png\")).values\n",
        "    train_labels = df[\"label\"].values\n",
        "    return train_data, train_labels\n",
        "\n",
        "# Model architecture\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        Flatten(input_shape=(32, 32, 3)),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Display image\n",
        "def display_image(image_data):\n",
        "    plt.figure(figsize=(1, 1))\n",
        "    plt.imshow(image_data)\n",
        "\n",
        "# Streamlit app\n",
        "def main():\n",
        "    st.title(\"Car Classification\")\n",
        "\n",
        "    st.write(\"### Load Data\")\n",
        "    data_path = \"data/cars.csv\"\n",
        "    train_data, train_labels = load_data(data_path)\n",
        "\n",
        "    st.write(\"### Model\")\n",
        "    model = create_model()\n",
        "\n",
        "    st.write(\"### Data Augmentation\")\n",
        "    data_gen = ImageDataGenerator(\n",
        "        rescale=1. / 255,\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    train_generator = data_gen.flow(train_data, train_labels, batch_size=32)\n",
        "\n",
        "    st.write(\"### Train Model\")\n",
        "    model.fit(train_generator, epochs=10)\n",
        "\n",
        "    st.write(\"### Classify Car\")\n",
        "    user_image = st.file_uploader(\"Upload an image\", type=\"png\")\n",
        "    if user_image:\n",
        "        user_image = Image.open(user_image)\n",
        "        st.image(user_image, caption=\"Uploaded image\", use_column_width=True)\n",
        "        user_image_data = np.array(user_image.resize((32, 32))) / 255.\n",
        "        user_image_data = np.expand_dims(user_image_data, axis=0)\n",
        "        user_image_data = np.expand_dims(user_image_data, axis=3)\n",
        "\n",
        "        prediction = model.predict(user_image_data)\n",
        "        probability = tf.nn.sigmoid(prediction)\n",
        "\n",
        "        st.write(\"### Prediction\")\n",
        "        display_image(user_image_data[0])\n",
        "        st.write(f\"Probability: {probability[0][0]:.3f}\")\n",
        "        if probability[0][0] > 0.5:\n",
        "            st.write(\"Prediction: Car\")\n",
        "        else:\n",
        "            st.write(\"Prediction: Not a car\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "l_SoB-mdwhOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code creates a simple Streamlit app with a car classification model. Users can upload an image, and the model will predict if the image contains a car or not. The model will also be trained using\n",
        "\n"
      ],
      "metadata": {
        "id": "5AArNInMwmND"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xCgMZO0awmv9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}