{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORoSREJ3DQIq5I0i+0S6dY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarMarhoun/freelance_work/blob/main/side_projects/NLP_projs/eda_streamlit/out_det2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Outlier detection of online price prediction dataset using streamlit and tensorflow\n",
        "\n",
        "To enhance the code for outlier detection of an online price prediction dataset using Streamlit and TensorFlow, you can create a user-friendly app that allows users to upload their dataset, preprocess the data, and visualize the outliers. Here's a code example that demonstrates this:\n",
        "\n",
        "First, install the necessary libraries:"
      ],
      "metadata": {
        "id": "OqtHTz9tJ_ED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit tensorflow numpy pandas scipy"
      ],
      "metadata": {
        "id": "aqfZAFuxKBUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a Python script (e.g., app.py) with the following code:\n"
      ],
      "metadata": {
        "id": "xfengmz1Ku1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Initialize the TensorFlow session\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "st.title(\"Outlier Detection for Online Price Prediction Dataset\")\n",
        "\n",
        "# Load dataset\n",
        "uploaded_file = st.file_uploader(\"Upload your dataset (CSV format)\", type=\"csv\")\n",
        "if uploaded_file:\n",
        "    df = pd.read_csv(uploaded_file)\n",
        "\n",
        "    # Preprocess data\n",
        "    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    df[numerical_cols] = df[numerical_cols].apply(zscore, axis=0)\n",
        "\n",
        "    # Visualize outliers\n",
        "    if st.button(\"Visualize Outliers\"):\n",
        "        st.write(\"## Outlier Visualization\")\n",
        "        st.write(\"The following plots show the outliers in the dataset.\")\n",
        "        for col in numerical_cols:\n",
        "            st.subheader(col)\n",
        "            st.write(df[col].plot(kind='box'))"
      ],
      "metadata": {
        "id": "2vOb8MpbKsts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the app using the following command:\n"
      ],
      "metadata": {
        "id": "8lgSJLm4K8vd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "streamlit run app.py"
      ],
      "metadata": {
        "id": "vTscSCreK9rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code example demonstrates how to create an interactive Streamlit app that allows users to upload their dataset (CSV format), preprocess the data (z-score normalization), and visualize the outliers in each numerical column.\n",
        "\n",
        "To further enhance the app, you can add more preprocessing options, use different outlier detection techniques, and improve data visualization. Additionally, you can integrate this app with your TensorFlow price prediction model to analyze the impact of outliers on your model's performance."
      ],
      "metadata": {
        "id": "QBprRTwlLoh5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MwvzF5rALpiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the article you provided, I will add some features to the previous Streamlit app for deploying a Deep Learning Classifier. I will include data validation, data preprocessing, and more interactive visualization.\n",
        "\n",
        "Create a new file named enhanced_app.py and add the following code:"
      ],
      "metadata": {
        "id": "bicJi0xyNWkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "# Load saved models and class names\n",
        "current_path = os.path.abspath(os.getcwd())\n",
        "model_path = os.path.join(current_path, 'static/dogbreed.h5')\n",
        "feature_extractor_path = os.path.join(current_path, 'static/feature_extractor.h5')\n",
        "class_names_path = os.path.join(current_path, 'static/dog_breeds_category.pickle')\n",
        "\n",
        "model = load_model(model_path)\n",
        "feature_extractor = load_model(feature_extractor_path)\n",
        "with open(class_names_path, 'rb') as class_file:\n",
        "    class_names = pickle.load(class_file)\n",
        "\n",
        "# Function to predict dog breed\n",
        "def predict_breed(image):\n",
        "    image = load_img(image, target_size=(331, 331))\n",
        "    image = img_to_array(image)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    features = feature_extractor.predict(image)\n",
        "    prediction = model.predict(features) * 100\n",
        "    prediction = pd.DataFrame(np.round(prediction, 1), columns=class_names).transpose()\n",
        "    prediction.columns = ['values']\n",
        "    prediction = prediction.nlargest(5, 'values')\n",
        "    prediction = prediction.reset_index()\n",
        "    prediction.columns = ['name', 'values']\n",
        "    return prediction\n",
        "\n",
        "# Streamlit app\n",
        "st.title(\"Dog Breed Classifier\")\n",
        "uploaded_file = st.file_uploader(\"Upload Image\", type=\"jpg\")\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    if os.path.exists(\"static/images\"):\n",
        "        pass\n",
        "    else:\n",
        "        os.mkdir(\"static/images\")\n",
        "\n",
        "    save_path = os.path.join(\"static/images\", uploaded_file.name)\n",
        "    with open(save_path, \"wb\") as f:\n",
        "        f.write(uploaded_file.getbuffer())\n",
        "\n",
        "    st.write(\"Classifying...\")\n",
        "    result = predict_breed(save_path)\n",
        "    st.success(\"Done!\")\n",
        "\n",
        "    st.subheader(\"Prediction\")\n",
        "    st.write(result)\n",
        "\n",
        "    # Display the uploaded image\n",
        "    st.write(\"## Uploaded Image\")\n",
        "    display_image = Image.open(uploaded_file)\n",
        "    st.image(display_image)\n",
        "\n",
        "    # Plot the top predictions\n",
        "    st.subheader(\"Top Predictions\")\n",
        "    fig, ax = plt.subplots()\n",
        "    ax = sns.barplot(y=\"name\", x=\"values\", data=result, order=result.sort_values('values', ascending=False)['name'])\n",
        "    ax.set(xlabel='Confidence %', ylabel='Breed')\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    # Remove the uploaded image\n",
        "    os.remove(save_path)\n",
        "else:\n",
        "    st.write(\"Please upload an image to classify.\")"
      ],
      "metadata": {
        "id": "NoqD_n-YNXYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the Streamlit app:\n"
      ],
      "metadata": {
        "id": "4LCw_r-yNcMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "streamlit run enhanced_app.py"
      ],
      "metadata": {
        "id": "kUsujj00NuTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This updated app includes the following enhancements:\n",
        "\n",
        "Validation of the uploaded file type\n",
        "\n",
        "Creation of an images directory if it does not already exist\n",
        "\n",
        "Saving the uploaded image to the images directory before processing\n",
        "\n",
        "Displaying the uploaded image along with the prediction result\n",
        "\n",
        "Plotting the top predictions using seaborn's barplot\n",
        "\n",
        "Removing the uploaded image from the images directory after processing"
      ],
      "metadata": {
        "id": "IoIP13jyN1IA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O3gY_DrqN0QZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To enhance and add more features to the existing outlier detection code, we can add functionality to save the results, customize the outlier threshold, and add a slider for selecting the top 'n' outliers. Here's the updated code:\n",
        "\n",
        "Create a directory tree as described in the article, and create a helper.py file to include the predictor function.\n",
        "\n",
        "Add the following code to the helper.py file:"
      ],
      "metadata": {
        "id": "wpg0AUnpP7Tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "def load_models():\n",
        "    current_path = os.getcwd()\n",
        "    dog_breeds_category_path = os.path.join(current_path, 'static\\dog_breeds_category.pickle')\n",
        "    feature_extractor = models.load_model(r'static\\feature_extractor.h5')\n",
        "    predictor_model = models.load_model(r'static\\dogbreed.h5')\n",
        "\n",
        "    with open(dog_breeds_category_path, 'rb') as handle:\n",
        "        dog_breeds = pickle.load(handle)\n",
        "\n",
        "    return feature_extractor, predictor_model, dog_breeds\n",
        "\n",
        "def predictor(img_path, threshold=3.0, n_top=5):\n",
        "    feature_extractor, predictor_model, dog_breeds = load_models()\n",
        "\n",
        "    img = load_img(img_path, target_size=(331,331))\n",
        "    img = img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    features = feature_extractor.predict(img)\n",
        "    prediction = predictor_model.predict(features) * 100\n",
        "    prediction_df = pd.DataFrame(np.round(prediction, 1), columns=dog_breeds).transpose()\n",
        "    prediction_df.columns = ['values']\n",
        "    prediction_df = prediction_df.nlargest(n_top, 'values')\n",
        "    prediction_df.index = ['name'] + ['-'.join(str(x).split('.')) for x in prediction_df.index]\n",
        "    prediction_df = prediction_df.reset_index(drop=True)\n",
        "\n",
        "    if prediction_df.loc[0, 'values'] < threshold:\n",
        "        return 0, 'No outlier detected'\n",
        "\n",
        "    return 1, prediction_df"
      ],
      "metadata": {
        "id": "oErOBYUUP8Bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the main.py file and add the following code:\n"
      ],
      "metadata": {
        "id": "bKITzKWGQA2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from helper import *\n",
        "\n",
        "st.title('Dog Breed Classifier')\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload Image\")\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    if save_uploaded_file(uploaded_file):\n",
        "        # display the image\n",
        "        display_image = Image.open(uploaded_file)\n",
        "        st.image(display_image)\n",
        "\n",
        "        threshold = st.slider('Outlier Threshold:', 1.0, 5.0, 3.0, 0.1)\n",
        "        n_top = st.number_input('Number of Top Predictions:', 1, 10, 5)\n",
        "\n",
        "        prediction, prediction_df = predictor(os.path.join('static/images', uploaded_file.name), threshold, n_top)\n",
        "\n",
        "        if prediction == 0:\n",
        "            st.text('No outlier detected')\n",
        "        else:\n",
        "            st.text('Predictions:')\n",
        "            fig, ax = plt.subplots()\n",
        "            ax = sns.barplot(y='name', x='values', data=prediction_df, order=prediction_df.sort_values('values', ascending=False).name)\n",
        "            ax.set(xlabel='Confidence %', ylabel='Breed')\n",
        "            st.pyplot(fig)"
      ],
      "metadata": {
        "id": "4MMMnebuQBdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This updated code includes the threshold and n_top parameters, allowing the user to customize the outlier detection and view the top 'n'"
      ],
      "metadata": {
        "id": "rbtcJUdfQGbk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sKZcZTubQHH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To add advanced features to the existing code for stroke risk prediction, we can implement the following improvements:\n",
        "\n",
        "Allow users to input all parameters present in the dataset (age, gender, bmi, avg glucose level, hypertension, heart disease).\n",
        "Save the model's predictions for user data.\n",
        "Display a summary of the user data provided.\n",
        "Here's the updated code:"
      ],
      "metadata": {
        "id": "K2VO4ruGRStk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "# Load your model (replace 'your_model.joblib' with your actual file path)\n",
        "loaded_model = joblib.load('your_model.joblib')\n",
        "\n",
        "# Set title of the Streamlit app\n",
        "st.title(\"Stroke Risk Prediction\")\n",
        "\n",
        "# Add user input section\n",
        "st.header(\"User Input\")\n",
        "user_age = st.slider(\"Age\", min_value=0, max_value=100, value=30)\n",
        "user_gender = st.radio(\"Gender\", [\"Male\", \"Female\"])\n",
        "user_bmi = st.number_input(\"BMI\", min_value=10.0, max_value=50.0, value=25.0)\n",
        "user_avg_glucose_level = st.number_input(\"Average Glucose Level\", min_value=0.0, value=80.0)\n",
        "user_hypertension = st.checkbox(\"Hypertension\")\n",
        "user_heart_disease = st.checkbox(\"Heart Disease\")\n",
        "user_submit = st.button(\"Predict\")\n",
        "\n",
        "# Prepare user data for prediction\n",
        "if user_submit:\n",
        "    # Create a DataFrame using user input\n",
        "    user_data_dict = {\n",
        "        \"age\": user_age,\n",
        "        \"gender\": user_gender,\n",
        "        \"bmi\": user_bmi,\n",
        "        \"avg_glucose_level\": user_avg_glucose_level,\n",
        "        \"hypertension\": user_hypertension,\n",
        "        \"heart_disease\": user_heart_disease\n",
        "    }\n",
        "\n",
        "    user_data = pd.DataFrame([user_data_dict])\n",
        "\n",
        "    # Preprocess user data\n",
        "    categorical_cols = ['gender', 'hypertension', 'heart_disease']\n",
        "    user_data[categorical_cols] = user_data[categorical_cols].astype('category').apply(lambda x: x.cat.codes)\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = loaded_model.predict(user_data)\n",
        "\n",
        "    # Display summary of the user data provided\n",
        "    st.subheader(\"User Data Summary\")\n",
        "    st.write(user_data)\n",
        "\n",
        "    # Display prediction\n",
        "    st.subheader(\"Stroke Risk Prediction\")\n",
        "    if prediction[0] == 0:\n",
        "        prediction_text = \"Low risk\"\n",
        "    else:\n",
        "        prediction_text = \"High risk\"\n",
        "    st.success(prediction_text)"
      ],
      "metadata": {
        "id": "fjABd_ZaRg2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This updated code includes input fields for all relevant parameters, saves the model's predictions for user data, and displays a summary of the user data provided. Make sure to replace your_model.joblib with the actual file path of your trained model.\n",
        "\n"
      ],
      "metadata": {
        "id": "3r8FiFbcRppw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yR7QSle6Rqdj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}